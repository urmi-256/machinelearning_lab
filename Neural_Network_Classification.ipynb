{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Neural_Network_Classification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/urmi-256/machinelearning_lab/blob/main/Neural_Network_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nhPEM4IUoDKA"
      },
      "source": [
        "CO CST IMPLEMENTATION OF NEURAL NETWORK\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZpJe0cAaoG98"
      },
      "source": [
        "# Tutorial 3: Neural Network Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dIT7QrK2PwdM"
      },
      "source": [
        "Dataset: [Pima Indian Diabetes Dataset](https://data.world/data-society/pima-indians-diabetes-database#)\n",
        "\n",
        "This dataset is originally from the National Institute of Diabetes and Digestive and Kidney Diseases. The objective is to predict based on diagnostic measurements whether a patient has diabetes.\n",
        "\n",
        "Several constraints were placed on the selection of these instances from a larger database. In particular, all patients here are females at least 21 years old of Pima Indian heritage.\n",
        "\n",
        "Attributes of PIMA dataset:\n",
        "\n",
        "**Pregnancies**: Number of times pregnant\n",
        "\n",
        "**Glucose**: Plasma glucose concentration a 2 hours in an oral glucose tolerance test\n",
        "\n",
        "**BloodPressure**: Diastolic blood pressure (mm Hg)\n",
        "\n",
        "**SkinThickness**: Triceps skin fold thickness (mm)\n",
        "\n",
        "**Insulin**: 2-Hour serum insulin (mu U/ml)\n",
        "\n",
        "**BMI**: Body mass index (weight in kg/(height in m)^2)\n",
        "\n",
        "**DiabetesPedigreeFunction**: Diabetes pedigree function\n",
        "\n",
        "**Age**: Age (years)\n",
        "\n",
        "**Outcome**: Class variable (0 or 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FIAgs3sTY712"
      },
      "source": [
        "**1. Mount the Google Drive**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CrZg_G5MQ4L5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d33243ff-e7c8-4f00-886c-61f5ded439ec"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CqAhYoWHZAwg"
      },
      "source": [
        "**2. Move to the place where data resides**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TjgG_3CiP4eQ",
        "outputId": "24a79ae9-3229-47a3-c083-dc515c359efb"
      },
      "source": [
        "%cd /content/drive/MyDrive/diabetes.csv"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 20] Not a directory: '/content/drive/MyDrive/diabetes.csv'\n",
            "/content/drive/MyDrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "id": "S-KhHH_xATY8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08b32e8e-1b98-4f2e-8178-5050b3c193af"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 0827CT191060.docx\n",
            " 0827CT191060.pdf\n",
            "'103_A Review _IP.pdf'\n",
            "'Admit Card.pdf'\n",
            " Classroom\n",
            "\"Codeforces 2.0's directory\"\n",
            "'Coding Club Report.pdf'\n",
            "'Colab Notebooks'\n",
            "'Computer network.gdoc'\n",
            "'Copy of Copy of Sequence Diagram (1).drawio'\n",
            "'Copy of Copy of Sequence Diagram.drawio'\n",
            "'Copy of Linear Regression .ipynb'\n",
            "'Copy of PERCEPTRON.ipynb'\n",
            "'Copy of petrol_consumption.csv'\n",
            "'Copy of Sequence Diagram.drawio'\n",
            "'CS and IT IV sem'\n",
            "'CST+CO II Online.xlsx'\n",
            "'data analtics.R'\n",
            "'dataset1 (1).csv'\n",
            " Deshaw\n",
            " diabetes.csv\n",
            "'Document from urmichauhan'\n",
            "'Document from urmichauhan (1)'\n",
            "'Document from urmichauhan.pdf'\n",
            "'Format for Minor Project Synopsis (1).docx'\n",
            "'Format for Minor Project Synopsis.docx'\n",
            "'Java- List of Experiment.docx'\n",
            " laptops.csv.gsheet\n",
            "'Leetcode Questions And solutions.gdoc'\n",
            "'Linear_Regression_Sklearn (1).ipynb'\n",
            " Linear_Regression_Sklearn.ipynb\n",
            "'Mastering Data Structures & Algorithms using C and C++'\n",
            " PERCEPTRON.ipynb\n",
            "'Problem Solving Basic.png'\n",
            " r3.Rhistory\n",
            "'\".:: Rajiv Gandhi Proudyogiki Vishwavidyalaya, Bhopal ::.\".pdf'\n",
            "'resume 01.docx'\n",
            "'Unit-4 (1).gdoc'\n",
            " Unit-4.gdoc\n",
            "'Untitled Diagram.drawio'\n",
            "'Untitled document (1).gdoc'\n",
            "'Untitled document (2).gdoc'\n",
            "'Untitled document (3).gdoc'\n",
            "'Untitled document (4).gdoc'\n",
            "'Untitled document (5).gdoc'\n",
            "'Untitled document.docx'\n",
            "'Untitled document.gdoc'\n",
            "'Urmi Chauhan (1).pdf'\n",
            "'Urmi Chauhan (2).pdf'\n",
            "'Urmi Chauhan (3).pdf'\n",
            "'Urmi Chauhan (4).pdf'\n",
            "'Urmi Chauhan (CT-60) Alexa (1).docx'\n",
            "'Urmi Chauhan (CT-60) Alexa.docx'\n",
            "'Urmi Chauhan ( CT -60).docx'\n",
            "'Urmi Chauhan(CT-60).docx'\n",
            "'Urmi Chauhan ( CT- 60 ).pdf'\n",
            "'Urmi Chauhan (CT-60).pdf'\n",
            "'Urmi Chauhan(CT-60) .pdf'\n",
            "'Urmi Chauhan(CT-60).pdf'\n",
            " Urmi_Chauhan_Essay.pdf\n",
            "'Urmi Chauhan (LOR).docx'\n",
            "'Urmi Chauhan (Open Source Contribution).jpeg'\n",
            "'Urmi Chauhan.pdf'\n",
            "'Urmi Chauhan (Scholarship Badge).png'\n",
            " urmi.pdf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "f65jHMx2I_1O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VKvfswsOZLUB"
      },
      "source": [
        "**3. Read the dataset from CSV file**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "32nNonRSSaQq",
        "outputId": "c6ab5ea6-0cad-4d3e-e553-4a6169b0f31d"
      },
      "source": [
        "import pandas as pd\n",
        "data = pd.read_csv('diabetes.csv')\n",
        "data.head(10)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
              "0            6      148             72             35        0  33.6   \n",
              "1            1       85             66             29        0  26.6   \n",
              "2            8      183             64              0        0  23.3   \n",
              "3            1       89             66             23       94  28.1   \n",
              "4            0      137             40             35      168  43.1   \n",
              "5            5      116             74              0        0  25.6   \n",
              "6            3       78             50             32       88  31.0   \n",
              "7           10      115              0              0        0  35.3   \n",
              "8            2      197             70             45      543  30.5   \n",
              "9            8      125             96              0        0   0.0   \n",
              "\n",
              "   DiabetesPedigreeFunction  Age  Outcome  \n",
              "0                     0.627   50        1  \n",
              "1                     0.351   31        0  \n",
              "2                     0.672   32        1  \n",
              "3                     0.167   21        0  \n",
              "4                     2.288   33        1  \n",
              "5                     0.201   30        0  \n",
              "6                     0.248   26        1  \n",
              "7                     0.134   29        0  \n",
              "8                     0.158   53        1  \n",
              "9                     0.232   54        1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b842d4cf-9b7d-4607-a6dd-29ff8e758302\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pregnancies</th>\n",
              "      <th>Glucose</th>\n",
              "      <th>BloodPressure</th>\n",
              "      <th>SkinThickness</th>\n",
              "      <th>Insulin</th>\n",
              "      <th>BMI</th>\n",
              "      <th>DiabetesPedigreeFunction</th>\n",
              "      <th>Age</th>\n",
              "      <th>Outcome</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6</td>\n",
              "      <td>148</td>\n",
              "      <td>72</td>\n",
              "      <td>35</td>\n",
              "      <td>0</td>\n",
              "      <td>33.6</td>\n",
              "      <td>0.627</td>\n",
              "      <td>50</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>85</td>\n",
              "      <td>66</td>\n",
              "      <td>29</td>\n",
              "      <td>0</td>\n",
              "      <td>26.6</td>\n",
              "      <td>0.351</td>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8</td>\n",
              "      <td>183</td>\n",
              "      <td>64</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>23.3</td>\n",
              "      <td>0.672</td>\n",
              "      <td>32</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>89</td>\n",
              "      <td>66</td>\n",
              "      <td>23</td>\n",
              "      <td>94</td>\n",
              "      <td>28.1</td>\n",
              "      <td>0.167</td>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>137</td>\n",
              "      <td>40</td>\n",
              "      <td>35</td>\n",
              "      <td>168</td>\n",
              "      <td>43.1</td>\n",
              "      <td>2.288</td>\n",
              "      <td>33</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>116</td>\n",
              "      <td>74</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>25.6</td>\n",
              "      <td>0.201</td>\n",
              "      <td>30</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>3</td>\n",
              "      <td>78</td>\n",
              "      <td>50</td>\n",
              "      <td>32</td>\n",
              "      <td>88</td>\n",
              "      <td>31.0</td>\n",
              "      <td>0.248</td>\n",
              "      <td>26</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>10</td>\n",
              "      <td>115</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>35.3</td>\n",
              "      <td>0.134</td>\n",
              "      <td>29</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>2</td>\n",
              "      <td>197</td>\n",
              "      <td>70</td>\n",
              "      <td>45</td>\n",
              "      <td>543</td>\n",
              "      <td>30.5</td>\n",
              "      <td>0.158</td>\n",
              "      <td>53</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>8</td>\n",
              "      <td>125</td>\n",
              "      <td>96</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.232</td>\n",
              "      <td>54</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b842d4cf-9b7d-4607-a6dd-29ff8e758302')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b842d4cf-9b7d-4607-a6dd-29ff8e758302 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b842d4cf-9b7d-4607-a6dd-29ff8e758302');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZrslDLESShr7",
        "outputId": "e4d0e9a3-b29c-4c6c-caae-3571d3627eb2"
      },
      "source": [
        "data.columns"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin',\n",
              "       'BMI', 'DiabetesPedigreeFunction', 'Age', 'Outcome'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BLElehZ-Skgq",
        "outputId": "f45fe4af-c665-46ee-9373-06b4c65db4aa"
      },
      "source": [
        "data.values"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  6.   , 148.   ,  72.   , ...,   0.627,  50.   ,   1.   ],\n",
              "       [  1.   ,  85.   ,  66.   , ...,   0.351,  31.   ,   0.   ],\n",
              "       [  8.   , 183.   ,  64.   , ...,   0.672,  32.   ,   1.   ],\n",
              "       ...,\n",
              "       [  5.   , 121.   ,  72.   , ...,   0.245,  30.   ,   0.   ],\n",
              "       [  1.   , 126.   ,  60.   , ...,   0.349,  47.   ,   1.   ],\n",
              "       [  1.   ,  93.   ,  70.   , ...,   0.315,  23.   ,   0.   ]])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2HnZxGc4ZQlf"
      },
      "source": [
        "**4. Store the data into input feature and label variables**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IPfA5BF0Sm4R",
        "outputId": "493abe29-fbd3-4e0d-c8dc-cc3632aa79fc"
      },
      "source": [
        "dataset= data.values\n",
        "X = dataset[:,0:8]\n",
        "Y = dataset[:,8]\n",
        "print(X)\n",
        "print(Y)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[  6.    148.     72.    ...  33.6     0.627  50.   ]\n",
            " [  1.     85.     66.    ...  26.6     0.351  31.   ]\n",
            " [  8.    183.     64.    ...  23.3     0.672  32.   ]\n",
            " ...\n",
            " [  5.    121.     72.    ...  26.2     0.245  30.   ]\n",
            " [  1.    126.     60.    ...  30.1     0.349  47.   ]\n",
            " [  1.     93.     70.    ...  30.4     0.315  23.   ]]\n",
            "[1. 0. 1. 0. 1. 0. 1. 0. 1. 1. 0. 1. 0. 1. 1. 1. 1. 1. 0. 1. 0. 0. 1. 1.\n",
            " 1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 1. 0. 1. 0. 0.\n",
            " 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0.\n",
            " 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0.\n",
            " 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 1. 1. 1. 0. 0. 0.\n",
            " 1. 0. 0. 0. 1. 1. 0. 0. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0.\n",
            " 0. 0. 1. 1. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 0. 0.\n",
            " 1. 1. 0. 1. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 1. 1. 1.\n",
            " 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 1. 1. 1. 1. 0.\n",
            " 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 1. 0. 0.\n",
            " 1. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1.\n",
            " 0. 0. 0. 1. 1. 1. 0. 0. 1. 0. 1. 0. 1. 1. 0. 1. 0. 0. 1. 0. 1. 1. 0. 0.\n",
            " 1. 0. 1. 0. 0. 1. 0. 1. 0. 1. 1. 1. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 0.\n",
            " 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 0. 1.\n",
            " 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0.\n",
            " 0. 0. 1. 1. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 1. 1. 0. 1. 0. 1. 0. 1. 0.\n",
            " 1. 1. 0. 0. 0. 0. 1. 1. 0. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 1. 0. 1. 0. 0.\n",
            " 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1.\n",
            " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
            " 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0.\n",
            " 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.\n",
            " 0. 1. 0. 1. 1. 0. 0. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 0. 1. 0. 0. 1. 0.\n",
            " 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 1.\n",
            " 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 1. 1. 1. 0. 1. 1. 0. 0. 0. 0.\n",
            " 0. 0. 0. 1. 1. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 1.\n",
            " 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 1. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1.\n",
            " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1.\n",
            " 0. 0. 1. 0. 1. 1. 1. 0. 0. 1. 1. 1. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OdPZerNUZV4Q"
      },
      "source": [
        "**5. Data Normalization**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pM4g3T1fWri-",
        "outputId": "5862b1cf-3cd1-4f2b-c608-5965bd21916d"
      },
      "source": [
        "from sklearn import preprocessing\n",
        "min_max_scaler = preprocessing.MinMaxScaler()\n",
        "X_scale = min_max_scaler.fit_transform(X)\n",
        "X_scale"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.35294118, 0.74371859, 0.59016393, ..., 0.50074516, 0.23441503,\n",
              "        0.48333333],\n",
              "       [0.05882353, 0.42713568, 0.54098361, ..., 0.39642325, 0.11656704,\n",
              "        0.16666667],\n",
              "       [0.47058824, 0.91959799, 0.52459016, ..., 0.34724292, 0.25362938,\n",
              "        0.18333333],\n",
              "       ...,\n",
              "       [0.29411765, 0.6080402 , 0.59016393, ..., 0.390462  , 0.07130658,\n",
              "        0.15      ],\n",
              "       [0.05882353, 0.63316583, 0.49180328, ..., 0.4485842 , 0.11571307,\n",
              "        0.43333333],\n",
              "       [0.05882353, 0.46733668, 0.57377049, ..., 0.45305514, 0.10119556,\n",
              "        0.03333333]])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n1B5x8C0ZY-e"
      },
      "source": [
        "**6. One-hot vector conversion**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IWPUAnA-XNd8",
        "outputId": "cdb8e6e0-f3b0-4071-a7a0-27923b0db02e"
      },
      "source": [
        "from keras.utils import np_utils\n",
        "encoded_y = np_utils.to_categorical(Y)\n",
        "encoded_y"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       ...,\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IeJWmMxjZbgo"
      },
      "source": [
        "**7. Split the dataset into training, testing and validation set**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3BqXnV1FXYIV",
        "outputId": "5396413c-8794-4950-e9b7-5ccda31bf871"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_training, X_testing, Y_training, Y_testing = train_test_split(X_scale, encoded_y, test_size=0.1, random_state=12)\n",
        "X_training, X_valid, Y_training, Y_valid = train_test_split(X_training, Y_training, test_size=0.1, random_state=12)\n",
        "print(len(X_training))\n",
        "print(len(X_testing))\n",
        "print(len(X_valid))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "621\n",
            "77\n",
            "70\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EH9IZizVZfKB"
      },
      "source": [
        "**8. Model Creation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hNfmvbMOXeku",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8b8d8a4-ef4b-4e3b-e805-56bb3184cedc"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "# Creating the model\n",
        "model = Sequential()\n",
        "model.add(Dense(24, input_shape=(8,), activation='sigmoid'))\n",
        "model.add(Dense(20, activation='tanh'))\n",
        "model.add(Dense(12, activation='relu'))\n",
        "model.add(Dense(2, activation='softmax'))\n",
        "model.summary()   #gives a summary of the model"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_10 (Dense)            (None, 24)                216       \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 20)                500       \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 12)                252       \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 2)                 26        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 994\n",
            "Trainable params: 994\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iYxZHI_EZiEF"
      },
      "source": [
        "**9. Model Compile**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "plF2qlxwXiIY"
      },
      "source": [
        "from tensorflow.keras import optimizers\n",
        "opt=optimizers.SGD(learning_rate=0.001)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E8VrUFVQZkNd"
      },
      "source": [
        "**10. Model Training**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "if you have 1000 training examples, and your batch size is  500, then it will take 2 iterations to complete 1 epoch."
      ],
      "metadata": {
        "id": "08Ul5lN90_Sp"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xhDZ8yPhXrs0",
        "outputId": "0eb6e06b-1427-4af4-9218-27ff0d008354"
      },
      "source": [
        "hist = model.fit(X_training, Y_training,batch_size=4,  epochs=750, validation_data=(X_valid,Y_valid))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/750\n",
            "156/156 [==============================] - 2s 7ms/step - loss: 0.4373 - accuracy: 0.7810 - val_loss: 0.4301 - val_accuracy: 0.7286\n",
            "Epoch 2/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4340 - accuracy: 0.7826 - val_loss: 0.4285 - val_accuracy: 0.7429\n",
            "Epoch 3/750\n",
            "156/156 [==============================] - 1s 6ms/step - loss: 0.4327 - accuracy: 0.7858 - val_loss: 0.4288 - val_accuracy: 0.7286\n",
            "Epoch 4/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4320 - accuracy: 0.7923 - val_loss: 0.4283 - val_accuracy: 0.7429\n",
            "Epoch 5/750\n",
            "156/156 [==============================] - 1s 6ms/step - loss: 0.4315 - accuracy: 0.7907 - val_loss: 0.4278 - val_accuracy: 0.7571\n",
            "Epoch 6/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4313 - accuracy: 0.7923 - val_loss: 0.4319 - val_accuracy: 0.7429\n",
            "Epoch 7/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4312 - accuracy: 0.7907 - val_loss: 0.4324 - val_accuracy: 0.7429\n",
            "Epoch 8/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4311 - accuracy: 0.7907 - val_loss: 0.4313 - val_accuracy: 0.7429\n",
            "Epoch 9/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4312 - accuracy: 0.7890 - val_loss: 0.4302 - val_accuracy: 0.7571\n",
            "Epoch 10/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4310 - accuracy: 0.7971 - val_loss: 0.4301 - val_accuracy: 0.7571\n",
            "Epoch 11/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4310 - accuracy: 0.7955 - val_loss: 0.4316 - val_accuracy: 0.7429\n",
            "Epoch 12/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4307 - accuracy: 0.7955 - val_loss: 0.4350 - val_accuracy: 0.7429\n",
            "Epoch 13/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4310 - accuracy: 0.7955 - val_loss: 0.4317 - val_accuracy: 0.7429\n",
            "Epoch 14/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4309 - accuracy: 0.7907 - val_loss: 0.4305 - val_accuracy: 0.7571\n",
            "Epoch 15/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4310 - accuracy: 0.7939 - val_loss: 0.4304 - val_accuracy: 0.7571\n",
            "Epoch 16/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4309 - accuracy: 0.7923 - val_loss: 0.4321 - val_accuracy: 0.7429\n",
            "Epoch 17/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4309 - accuracy: 0.7939 - val_loss: 0.4310 - val_accuracy: 0.7571\n",
            "Epoch 18/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4309 - accuracy: 0.7923 - val_loss: 0.4308 - val_accuracy: 0.7571\n",
            "Epoch 19/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4309 - accuracy: 0.7955 - val_loss: 0.4301 - val_accuracy: 0.7571\n",
            "Epoch 20/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4309 - accuracy: 0.7939 - val_loss: 0.4310 - val_accuracy: 0.7571\n",
            "Epoch 21/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4309 - accuracy: 0.7923 - val_loss: 0.4306 - val_accuracy: 0.7571\n",
            "Epoch 22/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4308 - accuracy: 0.7955 - val_loss: 0.4317 - val_accuracy: 0.7571\n",
            "Epoch 23/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4307 - accuracy: 0.7890 - val_loss: 0.4316 - val_accuracy: 0.7571\n",
            "Epoch 24/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4307 - accuracy: 0.7923 - val_loss: 0.4327 - val_accuracy: 0.7429\n",
            "Epoch 25/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4307 - accuracy: 0.7987 - val_loss: 0.4342 - val_accuracy: 0.7429\n",
            "Epoch 26/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4309 - accuracy: 0.7955 - val_loss: 0.4334 - val_accuracy: 0.7429\n",
            "Epoch 27/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4308 - accuracy: 0.7923 - val_loss: 0.4339 - val_accuracy: 0.7429\n",
            "Epoch 28/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4307 - accuracy: 0.7923 - val_loss: 0.4331 - val_accuracy: 0.7429\n",
            "Epoch 29/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4308 - accuracy: 0.7955 - val_loss: 0.4330 - val_accuracy: 0.7429\n",
            "Epoch 30/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4307 - accuracy: 0.7939 - val_loss: 0.4319 - val_accuracy: 0.7429\n",
            "Epoch 31/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4308 - accuracy: 0.7907 - val_loss: 0.4317 - val_accuracy: 0.7571\n",
            "Epoch 32/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4307 - accuracy: 0.7987 - val_loss: 0.4304 - val_accuracy: 0.7571\n",
            "Epoch 33/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4306 - accuracy: 0.7971 - val_loss: 0.4322 - val_accuracy: 0.7429\n",
            "Epoch 34/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4307 - accuracy: 0.7939 - val_loss: 0.4338 - val_accuracy: 0.7429\n",
            "Epoch 35/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4306 - accuracy: 0.7939 - val_loss: 0.4338 - val_accuracy: 0.7429\n",
            "Epoch 36/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4306 - accuracy: 0.7923 - val_loss: 0.4317 - val_accuracy: 0.7429\n",
            "Epoch 37/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4305 - accuracy: 0.7939 - val_loss: 0.4330 - val_accuracy: 0.7429\n",
            "Epoch 38/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4307 - accuracy: 0.7955 - val_loss: 0.4337 - val_accuracy: 0.7429\n",
            "Epoch 39/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4306 - accuracy: 0.7955 - val_loss: 0.4332 - val_accuracy: 0.7429\n",
            "Epoch 40/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4305 - accuracy: 0.7939 - val_loss: 0.4330 - val_accuracy: 0.7429\n",
            "Epoch 41/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4306 - accuracy: 0.7955 - val_loss: 0.4329 - val_accuracy: 0.7429\n",
            "Epoch 42/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4305 - accuracy: 0.7955 - val_loss: 0.4340 - val_accuracy: 0.7429\n",
            "Epoch 43/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4305 - accuracy: 0.7939 - val_loss: 0.4319 - val_accuracy: 0.7571\n",
            "Epoch 44/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4307 - accuracy: 0.7955 - val_loss: 0.4316 - val_accuracy: 0.7571\n",
            "Epoch 45/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4306 - accuracy: 0.7971 - val_loss: 0.4329 - val_accuracy: 0.7429\n",
            "Epoch 46/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4305 - accuracy: 0.7971 - val_loss: 0.4350 - val_accuracy: 0.7429\n",
            "Epoch 47/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4306 - accuracy: 0.7971 - val_loss: 0.4343 - val_accuracy: 0.7429\n",
            "Epoch 48/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4305 - accuracy: 0.7971 - val_loss: 0.4314 - val_accuracy: 0.7571\n",
            "Epoch 49/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4306 - accuracy: 0.7907 - val_loss: 0.4313 - val_accuracy: 0.7571\n",
            "Epoch 50/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4307 - accuracy: 0.7955 - val_loss: 0.4328 - val_accuracy: 0.7429\n",
            "Epoch 51/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4306 - accuracy: 0.7971 - val_loss: 0.4324 - val_accuracy: 0.7429\n",
            "Epoch 52/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4304 - accuracy: 0.7955 - val_loss: 0.4320 - val_accuracy: 0.7429\n",
            "Epoch 53/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4305 - accuracy: 0.7939 - val_loss: 0.4361 - val_accuracy: 0.7429\n",
            "Epoch 54/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4307 - accuracy: 0.7971 - val_loss: 0.4357 - val_accuracy: 0.7429\n",
            "Epoch 55/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4305 - accuracy: 0.7907 - val_loss: 0.4337 - val_accuracy: 0.7429\n",
            "Epoch 56/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4304 - accuracy: 0.7939 - val_loss: 0.4332 - val_accuracy: 0.7429\n",
            "Epoch 57/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4303 - accuracy: 0.7971 - val_loss: 0.4333 - val_accuracy: 0.7429\n",
            "Epoch 58/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4304 - accuracy: 0.7907 - val_loss: 0.4324 - val_accuracy: 0.7429\n",
            "Epoch 59/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4304 - accuracy: 0.7971 - val_loss: 0.4326 - val_accuracy: 0.7429\n",
            "Epoch 60/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4304 - accuracy: 0.7939 - val_loss: 0.4333 - val_accuracy: 0.7429\n",
            "Epoch 61/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4305 - accuracy: 0.7955 - val_loss: 0.4333 - val_accuracy: 0.7429\n",
            "Epoch 62/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4302 - accuracy: 0.7987 - val_loss: 0.4336 - val_accuracy: 0.7429\n",
            "Epoch 63/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4303 - accuracy: 0.7971 - val_loss: 0.4323 - val_accuracy: 0.7429\n",
            "Epoch 64/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4303 - accuracy: 0.7987 - val_loss: 0.4326 - val_accuracy: 0.7429\n",
            "Epoch 65/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4303 - accuracy: 0.7971 - val_loss: 0.4342 - val_accuracy: 0.7429\n",
            "Epoch 66/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4301 - accuracy: 0.7955 - val_loss: 0.4327 - val_accuracy: 0.7429\n",
            "Epoch 67/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4303 - accuracy: 0.7955 - val_loss: 0.4313 - val_accuracy: 0.7571\n",
            "Epoch 68/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4304 - accuracy: 0.7955 - val_loss: 0.4317 - val_accuracy: 0.7571\n",
            "Epoch 69/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4302 - accuracy: 0.7987 - val_loss: 0.4331 - val_accuracy: 0.7429\n",
            "Epoch 70/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4301 - accuracy: 0.7939 - val_loss: 0.4327 - val_accuracy: 0.7429\n",
            "Epoch 71/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4303 - accuracy: 0.7939 - val_loss: 0.4329 - val_accuracy: 0.7429\n",
            "Epoch 72/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4302 - accuracy: 0.7939 - val_loss: 0.4349 - val_accuracy: 0.7429\n",
            "Epoch 73/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4302 - accuracy: 0.7971 - val_loss: 0.4346 - val_accuracy: 0.7429\n",
            "Epoch 74/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4301 - accuracy: 0.7923 - val_loss: 0.4374 - val_accuracy: 0.7429\n",
            "Epoch 75/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4303 - accuracy: 0.7987 - val_loss: 0.4363 - val_accuracy: 0.7429\n",
            "Epoch 76/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4302 - accuracy: 0.7971 - val_loss: 0.4347 - val_accuracy: 0.7429\n",
            "Epoch 77/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4301 - accuracy: 0.7939 - val_loss: 0.4348 - val_accuracy: 0.7429\n",
            "Epoch 78/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4303 - accuracy: 0.7939 - val_loss: 0.4340 - val_accuracy: 0.7429\n",
            "Epoch 79/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4301 - accuracy: 0.7939 - val_loss: 0.4340 - val_accuracy: 0.7429\n",
            "Epoch 80/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4302 - accuracy: 0.7939 - val_loss: 0.4338 - val_accuracy: 0.7429\n",
            "Epoch 81/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4302 - accuracy: 0.7939 - val_loss: 0.4329 - val_accuracy: 0.7429\n",
            "Epoch 82/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4301 - accuracy: 0.7955 - val_loss: 0.4311 - val_accuracy: 0.7571\n",
            "Epoch 83/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4301 - accuracy: 0.7939 - val_loss: 0.4368 - val_accuracy: 0.7429\n",
            "Epoch 84/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4303 - accuracy: 0.8003 - val_loss: 0.4347 - val_accuracy: 0.7429\n",
            "Epoch 85/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4302 - accuracy: 0.7971 - val_loss: 0.4379 - val_accuracy: 0.7429\n",
            "Epoch 86/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4302 - accuracy: 0.7939 - val_loss: 0.4353 - val_accuracy: 0.7429\n",
            "Epoch 87/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4300 - accuracy: 0.7987 - val_loss: 0.4326 - val_accuracy: 0.7429\n",
            "Epoch 88/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4301 - accuracy: 0.7955 - val_loss: 0.4324 - val_accuracy: 0.7429\n",
            "Epoch 89/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4300 - accuracy: 0.7971 - val_loss: 0.4338 - val_accuracy: 0.7429\n",
            "Epoch 90/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4300 - accuracy: 0.7955 - val_loss: 0.4347 - val_accuracy: 0.7429\n",
            "Epoch 91/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4302 - accuracy: 0.7971 - val_loss: 0.4339 - val_accuracy: 0.7429\n",
            "Epoch 92/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4302 - accuracy: 0.7939 - val_loss: 0.4335 - val_accuracy: 0.7429\n",
            "Epoch 93/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4301 - accuracy: 0.7939 - val_loss: 0.4347 - val_accuracy: 0.7429\n",
            "Epoch 94/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4301 - accuracy: 0.7955 - val_loss: 0.4339 - val_accuracy: 0.7429\n",
            "Epoch 95/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4301 - accuracy: 0.7939 - val_loss: 0.4332 - val_accuracy: 0.7429\n",
            "Epoch 96/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4300 - accuracy: 0.7955 - val_loss: 0.4358 - val_accuracy: 0.7429\n",
            "Epoch 97/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4301 - accuracy: 0.7955 - val_loss: 0.4340 - val_accuracy: 0.7429\n",
            "Epoch 98/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4300 - accuracy: 0.7955 - val_loss: 0.4324 - val_accuracy: 0.7429\n",
            "Epoch 99/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4301 - accuracy: 0.7939 - val_loss: 0.4336 - val_accuracy: 0.7429\n",
            "Epoch 100/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4300 - accuracy: 0.7955 - val_loss: 0.4350 - val_accuracy: 0.7429\n",
            "Epoch 101/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4299 - accuracy: 0.7955 - val_loss: 0.4318 - val_accuracy: 0.7429\n",
            "Epoch 102/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4299 - accuracy: 0.7907 - val_loss: 0.4326 - val_accuracy: 0.7429\n",
            "Epoch 103/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4299 - accuracy: 0.7971 - val_loss: 0.4313 - val_accuracy: 0.7429\n",
            "Epoch 104/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4301 - accuracy: 0.7971 - val_loss: 0.4317 - val_accuracy: 0.7429\n",
            "Epoch 105/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4300 - accuracy: 0.7971 - val_loss: 0.4337 - val_accuracy: 0.7429\n",
            "Epoch 106/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4297 - accuracy: 0.7971 - val_loss: 0.4308 - val_accuracy: 0.7571\n",
            "Epoch 107/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4300 - accuracy: 0.7955 - val_loss: 0.4308 - val_accuracy: 0.7571\n",
            "Epoch 108/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4300 - accuracy: 0.7955 - val_loss: 0.4327 - val_accuracy: 0.7429\n",
            "Epoch 109/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4299 - accuracy: 0.7971 - val_loss: 0.4314 - val_accuracy: 0.7429\n",
            "Epoch 110/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4298 - accuracy: 0.7939 - val_loss: 0.4306 - val_accuracy: 0.7571\n",
            "Epoch 111/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4300 - accuracy: 0.7955 - val_loss: 0.4304 - val_accuracy: 0.7571\n",
            "Epoch 112/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4300 - accuracy: 0.7907 - val_loss: 0.4332 - val_accuracy: 0.7429\n",
            "Epoch 113/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4298 - accuracy: 0.7939 - val_loss: 0.4335 - val_accuracy: 0.7429\n",
            "Epoch 114/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4298 - accuracy: 0.7971 - val_loss: 0.4320 - val_accuracy: 0.7429\n",
            "Epoch 115/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4300 - accuracy: 0.7955 - val_loss: 0.4325 - val_accuracy: 0.7429\n",
            "Epoch 116/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4297 - accuracy: 0.7971 - val_loss: 0.4304 - val_accuracy: 0.7571\n",
            "Epoch 117/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4299 - accuracy: 0.7971 - val_loss: 0.4299 - val_accuracy: 0.7571\n",
            "Epoch 118/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4300 - accuracy: 0.7971 - val_loss: 0.4321 - val_accuracy: 0.7429\n",
            "Epoch 119/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4299 - accuracy: 0.7971 - val_loss: 0.4329 - val_accuracy: 0.7429\n",
            "Epoch 120/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4298 - accuracy: 0.7955 - val_loss: 0.4340 - val_accuracy: 0.7429\n",
            "Epoch 121/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4298 - accuracy: 0.7971 - val_loss: 0.4341 - val_accuracy: 0.7429\n",
            "Epoch 122/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4298 - accuracy: 0.7939 - val_loss: 0.4339 - val_accuracy: 0.7429\n",
            "Epoch 123/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4299 - accuracy: 0.7971 - val_loss: 0.4340 - val_accuracy: 0.7429\n",
            "Epoch 124/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4299 - accuracy: 0.7923 - val_loss: 0.4342 - val_accuracy: 0.7429\n",
            "Epoch 125/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4298 - accuracy: 0.7971 - val_loss: 0.4325 - val_accuracy: 0.7429\n",
            "Epoch 126/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4298 - accuracy: 0.7955 - val_loss: 0.4324 - val_accuracy: 0.7429\n",
            "Epoch 127/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4298 - accuracy: 0.7939 - val_loss: 0.4339 - val_accuracy: 0.7429\n",
            "Epoch 128/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4298 - accuracy: 0.7971 - val_loss: 0.4342 - val_accuracy: 0.7429\n",
            "Epoch 129/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4298 - accuracy: 0.7955 - val_loss: 0.4337 - val_accuracy: 0.7429\n",
            "Epoch 130/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4298 - accuracy: 0.7971 - val_loss: 0.4326 - val_accuracy: 0.7429\n",
            "Epoch 131/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4298 - accuracy: 0.7955 - val_loss: 0.4323 - val_accuracy: 0.7429\n",
            "Epoch 132/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4298 - accuracy: 0.7955 - val_loss: 0.4323 - val_accuracy: 0.7429\n",
            "Epoch 133/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4298 - accuracy: 0.7955 - val_loss: 0.4346 - val_accuracy: 0.7429\n",
            "Epoch 134/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4299 - accuracy: 0.7971 - val_loss: 0.4341 - val_accuracy: 0.7429\n",
            "Epoch 135/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4298 - accuracy: 0.7955 - val_loss: 0.4354 - val_accuracy: 0.7429\n",
            "Epoch 136/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4298 - accuracy: 0.7939 - val_loss: 0.4363 - val_accuracy: 0.7429\n",
            "Epoch 137/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4297 - accuracy: 0.7971 - val_loss: 0.4331 - val_accuracy: 0.7429\n",
            "Epoch 138/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4297 - accuracy: 0.7923 - val_loss: 0.4360 - val_accuracy: 0.7429\n",
            "Epoch 139/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4296 - accuracy: 0.7955 - val_loss: 0.4359 - val_accuracy: 0.7429\n",
            "Epoch 140/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4297 - accuracy: 0.8003 - val_loss: 0.4332 - val_accuracy: 0.7429\n",
            "Epoch 141/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4295 - accuracy: 0.7939 - val_loss: 0.4321 - val_accuracy: 0.7429\n",
            "Epoch 142/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4297 - accuracy: 0.7971 - val_loss: 0.4316 - val_accuracy: 0.7429\n",
            "Epoch 143/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4296 - accuracy: 0.7955 - val_loss: 0.4334 - val_accuracy: 0.7429\n",
            "Epoch 144/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4298 - accuracy: 0.7955 - val_loss: 0.4323 - val_accuracy: 0.7429\n",
            "Epoch 145/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4297 - accuracy: 0.7939 - val_loss: 0.4317 - val_accuracy: 0.7429\n",
            "Epoch 146/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4297 - accuracy: 0.7923 - val_loss: 0.4333 - val_accuracy: 0.7429\n",
            "Epoch 147/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4294 - accuracy: 0.7939 - val_loss: 0.4317 - val_accuracy: 0.7429\n",
            "Epoch 148/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4296 - accuracy: 0.7955 - val_loss: 0.4325 - val_accuracy: 0.7429\n",
            "Epoch 149/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4297 - accuracy: 0.7939 - val_loss: 0.4334 - val_accuracy: 0.7429\n",
            "Epoch 150/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4297 - accuracy: 0.7955 - val_loss: 0.4333 - val_accuracy: 0.7429\n",
            "Epoch 151/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4297 - accuracy: 0.7987 - val_loss: 0.4329 - val_accuracy: 0.7429\n",
            "Epoch 152/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4297 - accuracy: 0.7971 - val_loss: 0.4330 - val_accuracy: 0.7429\n",
            "Epoch 153/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4296 - accuracy: 0.7955 - val_loss: 0.4330 - val_accuracy: 0.7429\n",
            "Epoch 154/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4295 - accuracy: 0.7987 - val_loss: 0.4313 - val_accuracy: 0.7429\n",
            "Epoch 155/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4296 - accuracy: 0.7955 - val_loss: 0.4323 - val_accuracy: 0.7429\n",
            "Epoch 156/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4295 - accuracy: 0.7971 - val_loss: 0.4325 - val_accuracy: 0.7429\n",
            "Epoch 157/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4296 - accuracy: 0.7971 - val_loss: 0.4314 - val_accuracy: 0.7429\n",
            "Epoch 158/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4296 - accuracy: 0.7955 - val_loss: 0.4323 - val_accuracy: 0.7429\n",
            "Epoch 159/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4294 - accuracy: 0.7971 - val_loss: 0.4313 - val_accuracy: 0.7429\n",
            "Epoch 160/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4295 - accuracy: 0.7955 - val_loss: 0.4342 - val_accuracy: 0.7429\n",
            "Epoch 161/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4295 - accuracy: 0.7971 - val_loss: 0.4357 - val_accuracy: 0.7429\n",
            "Epoch 162/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4294 - accuracy: 0.7955 - val_loss: 0.4341 - val_accuracy: 0.7429\n",
            "Epoch 163/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4294 - accuracy: 0.7971 - val_loss: 0.4350 - val_accuracy: 0.7429\n",
            "Epoch 164/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4294 - accuracy: 0.7971 - val_loss: 0.4344 - val_accuracy: 0.7429\n",
            "Epoch 165/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4295 - accuracy: 0.7971 - val_loss: 0.4330 - val_accuracy: 0.7429\n",
            "Epoch 166/750\n",
            "156/156 [==============================] - 1s 3ms/step - loss: 0.4295 - accuracy: 0.7971 - val_loss: 0.4330 - val_accuracy: 0.7429\n",
            "Epoch 167/750\n",
            "156/156 [==============================] - 1s 4ms/step - loss: 0.4295 - accuracy: 0.7987 - val_loss: 0.4361 - val_accuracy: 0.7429\n",
            "Epoch 168/750\n",
            "156/156 [==============================] - 1s 4ms/step - loss: 0.4296 - accuracy: 0.7971 - val_loss: 0.4355 - val_accuracy: 0.7429\n",
            "Epoch 169/750\n",
            "156/156 [==============================] - 1s 5ms/step - loss: 0.4294 - accuracy: 0.7955 - val_loss: 0.4377 - val_accuracy: 0.7429\n",
            "Epoch 170/750\n",
            "156/156 [==============================] - 1s 5ms/step - loss: 0.4295 - accuracy: 0.7971 - val_loss: 0.4346 - val_accuracy: 0.7429\n",
            "Epoch 171/750\n",
            "156/156 [==============================] - 1s 6ms/step - loss: 0.4295 - accuracy: 0.7955 - val_loss: 0.4364 - val_accuracy: 0.7429\n",
            "Epoch 172/750\n",
            "156/156 [==============================] - 1s 5ms/step - loss: 0.4292 - accuracy: 0.8003 - val_loss: 0.4318 - val_accuracy: 0.7429\n",
            "Epoch 173/750\n",
            "156/156 [==============================] - 1s 4ms/step - loss: 0.4294 - accuracy: 0.7971 - val_loss: 0.4328 - val_accuracy: 0.7429\n",
            "Epoch 174/750\n",
            "156/156 [==============================] - 1s 5ms/step - loss: 0.4295 - accuracy: 0.7971 - val_loss: 0.4325 - val_accuracy: 0.7429\n",
            "Epoch 175/750\n",
            "156/156 [==============================] - 1s 5ms/step - loss: 0.4296 - accuracy: 0.7971 - val_loss: 0.4340 - val_accuracy: 0.7429\n",
            "Epoch 176/750\n",
            "156/156 [==============================] - 1s 4ms/step - loss: 0.4294 - accuracy: 0.7987 - val_loss: 0.4344 - val_accuracy: 0.7429\n",
            "Epoch 177/750\n",
            "156/156 [==============================] - 1s 4ms/step - loss: 0.4293 - accuracy: 0.7971 - val_loss: 0.4356 - val_accuracy: 0.7429\n",
            "Epoch 178/750\n",
            "156/156 [==============================] - 1s 5ms/step - loss: 0.4294 - accuracy: 0.7971 - val_loss: 0.4336 - val_accuracy: 0.7429\n",
            "Epoch 179/750\n",
            "156/156 [==============================] - 1s 7ms/step - loss: 0.4294 - accuracy: 0.7939 - val_loss: 0.4327 - val_accuracy: 0.7429\n",
            "Epoch 180/750\n",
            "156/156 [==============================] - 0s 3ms/step - loss: 0.4294 - accuracy: 0.7971 - val_loss: 0.4352 - val_accuracy: 0.7429\n",
            "Epoch 181/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4293 - accuracy: 0.7987 - val_loss: 0.4331 - val_accuracy: 0.7429\n",
            "Epoch 182/750\n",
            "156/156 [==============================] - 0s 3ms/step - loss: 0.4293 - accuracy: 0.7987 - val_loss: 0.4349 - val_accuracy: 0.7429\n",
            "Epoch 183/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4293 - accuracy: 0.7939 - val_loss: 0.4325 - val_accuracy: 0.7429\n",
            "Epoch 184/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4295 - accuracy: 0.7955 - val_loss: 0.4333 - val_accuracy: 0.7429\n",
            "Epoch 185/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4292 - accuracy: 0.7939 - val_loss: 0.4335 - val_accuracy: 0.7429\n",
            "Epoch 186/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4293 - accuracy: 0.7939 - val_loss: 0.4365 - val_accuracy: 0.7429\n",
            "Epoch 187/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4292 - accuracy: 0.7987 - val_loss: 0.4344 - val_accuracy: 0.7429\n",
            "Epoch 188/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4293 - accuracy: 0.7987 - val_loss: 0.4334 - val_accuracy: 0.7429\n",
            "Epoch 189/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4293 - accuracy: 0.7971 - val_loss: 0.4339 - val_accuracy: 0.7429\n",
            "Epoch 190/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4295 - accuracy: 0.7971 - val_loss: 0.4347 - val_accuracy: 0.7429\n",
            "Epoch 191/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4292 - accuracy: 0.7987 - val_loss: 0.4331 - val_accuracy: 0.7429\n",
            "Epoch 192/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4293 - accuracy: 0.7987 - val_loss: 0.4334 - val_accuracy: 0.7429\n",
            "Epoch 193/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4293 - accuracy: 0.7907 - val_loss: 0.4375 - val_accuracy: 0.7429\n",
            "Epoch 194/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4293 - accuracy: 0.7971 - val_loss: 0.4345 - val_accuracy: 0.7429\n",
            "Epoch 195/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4293 - accuracy: 0.7971 - val_loss: 0.4369 - val_accuracy: 0.7429\n",
            "Epoch 196/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4291 - accuracy: 0.7971 - val_loss: 0.4326 - val_accuracy: 0.7429\n",
            "Epoch 197/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4293 - accuracy: 0.7955 - val_loss: 0.4342 - val_accuracy: 0.7429\n",
            "Epoch 198/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4293 - accuracy: 0.7987 - val_loss: 0.4329 - val_accuracy: 0.7429\n",
            "Epoch 199/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4291 - accuracy: 0.7971 - val_loss: 0.4311 - val_accuracy: 0.7429\n",
            "Epoch 200/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4292 - accuracy: 0.7939 - val_loss: 0.4346 - val_accuracy: 0.7429\n",
            "Epoch 201/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4292 - accuracy: 0.7971 - val_loss: 0.4342 - val_accuracy: 0.7429\n",
            "Epoch 202/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4293 - accuracy: 0.7971 - val_loss: 0.4337 - val_accuracy: 0.7429\n",
            "Epoch 203/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4291 - accuracy: 0.7987 - val_loss: 0.4356 - val_accuracy: 0.7429\n",
            "Epoch 204/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4293 - accuracy: 0.7939 - val_loss: 0.4331 - val_accuracy: 0.7429\n",
            "Epoch 205/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4293 - accuracy: 0.7955 - val_loss: 0.4341 - val_accuracy: 0.7429\n",
            "Epoch 206/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4291 - accuracy: 0.7971 - val_loss: 0.4326 - val_accuracy: 0.7429\n",
            "Epoch 207/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4293 - accuracy: 0.7971 - val_loss: 0.4338 - val_accuracy: 0.7429\n",
            "Epoch 208/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4293 - accuracy: 0.7955 - val_loss: 0.4333 - val_accuracy: 0.7429\n",
            "Epoch 209/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4291 - accuracy: 0.7955 - val_loss: 0.4350 - val_accuracy: 0.7429\n",
            "Epoch 210/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4292 - accuracy: 0.7971 - val_loss: 0.4339 - val_accuracy: 0.7429\n",
            "Epoch 211/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4291 - accuracy: 0.7971 - val_loss: 0.4335 - val_accuracy: 0.7429\n",
            "Epoch 212/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4292 - accuracy: 0.7971 - val_loss: 0.4331 - val_accuracy: 0.7429\n",
            "Epoch 213/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4293 - accuracy: 0.7971 - val_loss: 0.4339 - val_accuracy: 0.7429\n",
            "Epoch 214/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4291 - accuracy: 0.7971 - val_loss: 0.4339 - val_accuracy: 0.7429\n",
            "Epoch 215/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4291 - accuracy: 0.7987 - val_loss: 0.4343 - val_accuracy: 0.7429\n",
            "Epoch 216/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4291 - accuracy: 0.7955 - val_loss: 0.4335 - val_accuracy: 0.7429\n",
            "Epoch 217/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4290 - accuracy: 0.7987 - val_loss: 0.4330 - val_accuracy: 0.7429\n",
            "Epoch 218/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4292 - accuracy: 0.7939 - val_loss: 0.4343 - val_accuracy: 0.7429\n",
            "Epoch 219/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4290 - accuracy: 0.7987 - val_loss: 0.4319 - val_accuracy: 0.7429\n",
            "Epoch 220/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4292 - accuracy: 0.7955 - val_loss: 0.4329 - val_accuracy: 0.7429\n",
            "Epoch 221/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4292 - accuracy: 0.7955 - val_loss: 0.4327 - val_accuracy: 0.7429\n",
            "Epoch 222/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4291 - accuracy: 0.7987 - val_loss: 0.4329 - val_accuracy: 0.7429\n",
            "Epoch 223/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4292 - accuracy: 0.7955 - val_loss: 0.4331 - val_accuracy: 0.7429\n",
            "Epoch 224/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4291 - accuracy: 0.7955 - val_loss: 0.4345 - val_accuracy: 0.7429\n",
            "Epoch 225/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4289 - accuracy: 0.7955 - val_loss: 0.4325 - val_accuracy: 0.7429\n",
            "Epoch 226/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4292 - accuracy: 0.7955 - val_loss: 0.4332 - val_accuracy: 0.7429\n",
            "Epoch 227/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4290 - accuracy: 0.7987 - val_loss: 0.4334 - val_accuracy: 0.7429\n",
            "Epoch 228/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4291 - accuracy: 0.7987 - val_loss: 0.4333 - val_accuracy: 0.7429\n",
            "Epoch 229/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4290 - accuracy: 0.7955 - val_loss: 0.4376 - val_accuracy: 0.7429\n",
            "Epoch 230/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4291 - accuracy: 0.7971 - val_loss: 0.4349 - val_accuracy: 0.7429\n",
            "Epoch 231/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4288 - accuracy: 0.8003 - val_loss: 0.4321 - val_accuracy: 0.7429\n",
            "Epoch 232/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4291 - accuracy: 0.7971 - val_loss: 0.4332 - val_accuracy: 0.7429\n",
            "Epoch 233/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4291 - accuracy: 0.7955 - val_loss: 0.4319 - val_accuracy: 0.7429\n",
            "Epoch 234/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4290 - accuracy: 0.7939 - val_loss: 0.4316 - val_accuracy: 0.7429\n",
            "Epoch 235/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4289 - accuracy: 0.7971 - val_loss: 0.4333 - val_accuracy: 0.7429\n",
            "Epoch 236/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4291 - accuracy: 0.7971 - val_loss: 0.4329 - val_accuracy: 0.7429\n",
            "Epoch 237/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4290 - accuracy: 0.7955 - val_loss: 0.4350 - val_accuracy: 0.7429\n",
            "Epoch 238/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4290 - accuracy: 0.8003 - val_loss: 0.4335 - val_accuracy: 0.7429\n",
            "Epoch 239/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4291 - accuracy: 0.7971 - val_loss: 0.4334 - val_accuracy: 0.7429\n",
            "Epoch 240/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4289 - accuracy: 0.7971 - val_loss: 0.4338 - val_accuracy: 0.7429\n",
            "Epoch 241/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4290 - accuracy: 0.7955 - val_loss: 0.4329 - val_accuracy: 0.7429\n",
            "Epoch 242/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4289 - accuracy: 0.8003 - val_loss: 0.4332 - val_accuracy: 0.7429\n",
            "Epoch 243/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4289 - accuracy: 0.7939 - val_loss: 0.4352 - val_accuracy: 0.7429\n",
            "Epoch 244/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4290 - accuracy: 0.8003 - val_loss: 0.4337 - val_accuracy: 0.7429\n",
            "Epoch 245/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4291 - accuracy: 0.7955 - val_loss: 0.4332 - val_accuracy: 0.7429\n",
            "Epoch 246/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4290 - accuracy: 0.7955 - val_loss: 0.4342 - val_accuracy: 0.7429\n",
            "Epoch 247/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4289 - accuracy: 0.7971 - val_loss: 0.4359 - val_accuracy: 0.7429\n",
            "Epoch 248/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4289 - accuracy: 0.7939 - val_loss: 0.4337 - val_accuracy: 0.7429\n",
            "Epoch 249/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4288 - accuracy: 0.7987 - val_loss: 0.4325 - val_accuracy: 0.7429\n",
            "Epoch 250/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4289 - accuracy: 0.7955 - val_loss: 0.4336 - val_accuracy: 0.7429\n",
            "Epoch 251/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4289 - accuracy: 0.7987 - val_loss: 0.4347 - val_accuracy: 0.7429\n",
            "Epoch 252/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4289 - accuracy: 0.7971 - val_loss: 0.4344 - val_accuracy: 0.7429\n",
            "Epoch 253/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4290 - accuracy: 0.7971 - val_loss: 0.4329 - val_accuracy: 0.7429\n",
            "Epoch 254/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4288 - accuracy: 0.7987 - val_loss: 0.4317 - val_accuracy: 0.7429\n",
            "Epoch 255/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4288 - accuracy: 0.7971 - val_loss: 0.4333 - val_accuracy: 0.7429\n",
            "Epoch 256/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4289 - accuracy: 0.7971 - val_loss: 0.4338 - val_accuracy: 0.7429\n",
            "Epoch 257/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4290 - accuracy: 0.7971 - val_loss: 0.4350 - val_accuracy: 0.7429\n",
            "Epoch 258/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4288 - accuracy: 0.7971 - val_loss: 0.4335 - val_accuracy: 0.7429\n",
            "Epoch 259/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4289 - accuracy: 0.7971 - val_loss: 0.4338 - val_accuracy: 0.7429\n",
            "Epoch 260/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4289 - accuracy: 0.7939 - val_loss: 0.4339 - val_accuracy: 0.7429\n",
            "Epoch 261/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4288 - accuracy: 0.7987 - val_loss: 0.4315 - val_accuracy: 0.7429\n",
            "Epoch 262/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4289 - accuracy: 0.7923 - val_loss: 0.4342 - val_accuracy: 0.7429\n",
            "Epoch 263/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4289 - accuracy: 0.7955 - val_loss: 0.4349 - val_accuracy: 0.7429\n",
            "Epoch 264/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4288 - accuracy: 0.7987 - val_loss: 0.4331 - val_accuracy: 0.7429\n",
            "Epoch 265/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4288 - accuracy: 0.7987 - val_loss: 0.4324 - val_accuracy: 0.7429\n",
            "Epoch 266/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4288 - accuracy: 0.7955 - val_loss: 0.4346 - val_accuracy: 0.7429\n",
            "Epoch 267/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4289 - accuracy: 0.7987 - val_loss: 0.4348 - val_accuracy: 0.7429\n",
            "Epoch 268/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4288 - accuracy: 0.7971 - val_loss: 0.4356 - val_accuracy: 0.7429\n",
            "Epoch 269/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4288 - accuracy: 0.7971 - val_loss: 0.4345 - val_accuracy: 0.7429\n",
            "Epoch 270/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4288 - accuracy: 0.7971 - val_loss: 0.4346 - val_accuracy: 0.7429\n",
            "Epoch 271/750\n",
            "156/156 [==============================] - 0s 3ms/step - loss: 0.4289 - accuracy: 0.7987 - val_loss: 0.4330 - val_accuracy: 0.7429\n",
            "Epoch 272/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4288 - accuracy: 0.7987 - val_loss: 0.4331 - val_accuracy: 0.7429\n",
            "Epoch 273/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4287 - accuracy: 0.8003 - val_loss: 0.4338 - val_accuracy: 0.7429\n",
            "Epoch 274/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4289 - accuracy: 0.8003 - val_loss: 0.4325 - val_accuracy: 0.7429\n",
            "Epoch 275/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4287 - accuracy: 0.8003 - val_loss: 0.4303 - val_accuracy: 0.7429\n",
            "Epoch 276/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4289 - accuracy: 0.7971 - val_loss: 0.4330 - val_accuracy: 0.7429\n",
            "Epoch 277/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4288 - accuracy: 0.7971 - val_loss: 0.4345 - val_accuracy: 0.7429\n",
            "Epoch 278/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4287 - accuracy: 0.7987 - val_loss: 0.4353 - val_accuracy: 0.7429\n",
            "Epoch 279/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4286 - accuracy: 0.7955 - val_loss: 0.4328 - val_accuracy: 0.7429\n",
            "Epoch 280/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4288 - accuracy: 0.7939 - val_loss: 0.4335 - val_accuracy: 0.7429\n",
            "Epoch 281/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4288 - accuracy: 0.7971 - val_loss: 0.4343 - val_accuracy: 0.7429\n",
            "Epoch 282/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4286 - accuracy: 0.7971 - val_loss: 0.4347 - val_accuracy: 0.7429\n",
            "Epoch 283/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4286 - accuracy: 0.7939 - val_loss: 0.4333 - val_accuracy: 0.7429\n",
            "Epoch 284/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4287 - accuracy: 0.8003 - val_loss: 0.4335 - val_accuracy: 0.7429\n",
            "Epoch 285/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4287 - accuracy: 0.7987 - val_loss: 0.4330 - val_accuracy: 0.7429\n",
            "Epoch 286/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4289 - accuracy: 0.7955 - val_loss: 0.4349 - val_accuracy: 0.7429\n",
            "Epoch 287/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4287 - accuracy: 0.7939 - val_loss: 0.4341 - val_accuracy: 0.7429\n",
            "Epoch 288/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4287 - accuracy: 0.7987 - val_loss: 0.4361 - val_accuracy: 0.7429\n",
            "Epoch 289/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4287 - accuracy: 0.7955 - val_loss: 0.4350 - val_accuracy: 0.7429\n",
            "Epoch 290/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4286 - accuracy: 0.7971 - val_loss: 0.4342 - val_accuracy: 0.7429\n",
            "Epoch 291/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4287 - accuracy: 0.7987 - val_loss: 0.4339 - val_accuracy: 0.7429\n",
            "Epoch 292/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4285 - accuracy: 0.7955 - val_loss: 0.4373 - val_accuracy: 0.7429\n",
            "Epoch 293/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4288 - accuracy: 0.7971 - val_loss: 0.4342 - val_accuracy: 0.7429\n",
            "Epoch 294/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4285 - accuracy: 0.7955 - val_loss: 0.4346 - val_accuracy: 0.7429\n",
            "Epoch 295/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4287 - accuracy: 0.7939 - val_loss: 0.4344 - val_accuracy: 0.7429\n",
            "Epoch 296/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4286 - accuracy: 0.7971 - val_loss: 0.4324 - val_accuracy: 0.7429\n",
            "Epoch 297/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4287 - accuracy: 0.7955 - val_loss: 0.4327 - val_accuracy: 0.7429\n",
            "Epoch 298/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4285 - accuracy: 0.7971 - val_loss: 0.4357 - val_accuracy: 0.7429\n",
            "Epoch 299/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4287 - accuracy: 0.7955 - val_loss: 0.4332 - val_accuracy: 0.7429\n",
            "Epoch 300/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4287 - accuracy: 0.7939 - val_loss: 0.4352 - val_accuracy: 0.7429\n",
            "Epoch 301/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4286 - accuracy: 0.7955 - val_loss: 0.4350 - val_accuracy: 0.7429\n",
            "Epoch 302/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4285 - accuracy: 0.7955 - val_loss: 0.4321 - val_accuracy: 0.7429\n",
            "Epoch 303/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4287 - accuracy: 0.7955 - val_loss: 0.4316 - val_accuracy: 0.7429\n",
            "Epoch 304/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4285 - accuracy: 0.7971 - val_loss: 0.4288 - val_accuracy: 0.7571\n",
            "Epoch 305/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4289 - accuracy: 0.7987 - val_loss: 0.4315 - val_accuracy: 0.7429\n",
            "Epoch 306/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4286 - accuracy: 0.7971 - val_loss: 0.4320 - val_accuracy: 0.7429\n",
            "Epoch 307/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4286 - accuracy: 0.7971 - val_loss: 0.4341 - val_accuracy: 0.7429\n",
            "Epoch 308/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4286 - accuracy: 0.7955 - val_loss: 0.4348 - val_accuracy: 0.7429\n",
            "Epoch 309/750\n",
            "156/156 [==============================] - 0s 3ms/step - loss: 0.4288 - accuracy: 0.7987 - val_loss: 0.4338 - val_accuracy: 0.7429\n",
            "Epoch 310/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4286 - accuracy: 0.7987 - val_loss: 0.4333 - val_accuracy: 0.7429\n",
            "Epoch 311/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4287 - accuracy: 0.7955 - val_loss: 0.4328 - val_accuracy: 0.7429\n",
            "Epoch 312/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4285 - accuracy: 0.7971 - val_loss: 0.4324 - val_accuracy: 0.7429\n",
            "Epoch 313/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4285 - accuracy: 0.7939 - val_loss: 0.4337 - val_accuracy: 0.7429\n",
            "Epoch 314/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4286 - accuracy: 0.7971 - val_loss: 0.4350 - val_accuracy: 0.7429\n",
            "Epoch 315/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4287 - accuracy: 0.7971 - val_loss: 0.4333 - val_accuracy: 0.7429\n",
            "Epoch 316/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4285 - accuracy: 0.7987 - val_loss: 0.4359 - val_accuracy: 0.7429\n",
            "Epoch 317/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4286 - accuracy: 0.7971 - val_loss: 0.4346 - val_accuracy: 0.7429\n",
            "Epoch 318/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4282 - accuracy: 0.7955 - val_loss: 0.4318 - val_accuracy: 0.7429\n",
            "Epoch 319/750\n",
            "156/156 [==============================] - 0s 3ms/step - loss: 0.4286 - accuracy: 0.7987 - val_loss: 0.4325 - val_accuracy: 0.7429\n",
            "Epoch 320/750\n",
            "156/156 [==============================] - 0s 3ms/step - loss: 0.4285 - accuracy: 0.7971 - val_loss: 0.4328 - val_accuracy: 0.7429\n",
            "Epoch 321/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4286 - accuracy: 0.7987 - val_loss: 0.4341 - val_accuracy: 0.7429\n",
            "Epoch 322/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4284 - accuracy: 0.7971 - val_loss: 0.4347 - val_accuracy: 0.7429\n",
            "Epoch 323/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4285 - accuracy: 0.7971 - val_loss: 0.4355 - val_accuracy: 0.7429\n",
            "Epoch 324/750\n",
            "156/156 [==============================] - 0s 3ms/step - loss: 0.4284 - accuracy: 0.7955 - val_loss: 0.4346 - val_accuracy: 0.7429\n",
            "Epoch 325/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4283 - accuracy: 0.7971 - val_loss: 0.4362 - val_accuracy: 0.7429\n",
            "Epoch 326/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4285 - accuracy: 0.7955 - val_loss: 0.4393 - val_accuracy: 0.7429\n",
            "Epoch 327/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4287 - accuracy: 0.7971 - val_loss: 0.4351 - val_accuracy: 0.7429\n",
            "Epoch 328/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4285 - accuracy: 0.7987 - val_loss: 0.4339 - val_accuracy: 0.7429\n",
            "Epoch 329/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4285 - accuracy: 0.7987 - val_loss: 0.4341 - val_accuracy: 0.7429\n",
            "Epoch 330/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4284 - accuracy: 0.7907 - val_loss: 0.4349 - val_accuracy: 0.7429\n",
            "Epoch 331/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4285 - accuracy: 0.7987 - val_loss: 0.4337 - val_accuracy: 0.7429\n",
            "Epoch 332/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4284 - accuracy: 0.8003 - val_loss: 0.4342 - val_accuracy: 0.7429\n",
            "Epoch 333/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4284 - accuracy: 0.7987 - val_loss: 0.4345 - val_accuracy: 0.7429\n",
            "Epoch 334/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4283 - accuracy: 0.7971 - val_loss: 0.4364 - val_accuracy: 0.7429\n",
            "Epoch 335/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4284 - accuracy: 0.7971 - val_loss: 0.4358 - val_accuracy: 0.7429\n",
            "Epoch 336/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4282 - accuracy: 0.7971 - val_loss: 0.4317 - val_accuracy: 0.7429\n",
            "Epoch 337/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4284 - accuracy: 0.7971 - val_loss: 0.4312 - val_accuracy: 0.7429\n",
            "Epoch 338/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4285 - accuracy: 0.7987 - val_loss: 0.4335 - val_accuracy: 0.7429\n",
            "Epoch 339/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4284 - accuracy: 0.7971 - val_loss: 0.4331 - val_accuracy: 0.7429\n",
            "Epoch 340/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4283 - accuracy: 0.7955 - val_loss: 0.4356 - val_accuracy: 0.7429\n",
            "Epoch 341/750\n",
            "156/156 [==============================] - 0s 3ms/step - loss: 0.4284 - accuracy: 0.7955 - val_loss: 0.4375 - val_accuracy: 0.7429\n",
            "Epoch 342/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4285 - accuracy: 0.8003 - val_loss: 0.4338 - val_accuracy: 0.7429\n",
            "Epoch 343/750\n",
            "156/156 [==============================] - 0s 3ms/step - loss: 0.4284 - accuracy: 0.8003 - val_loss: 0.4327 - val_accuracy: 0.7429\n",
            "Epoch 344/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4282 - accuracy: 0.7987 - val_loss: 0.4301 - val_accuracy: 0.7429\n",
            "Epoch 345/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4286 - accuracy: 0.7939 - val_loss: 0.4318 - val_accuracy: 0.7429\n",
            "Epoch 346/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4285 - accuracy: 0.7987 - val_loss: 0.4324 - val_accuracy: 0.7429\n",
            "Epoch 347/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4283 - accuracy: 0.8019 - val_loss: 0.4322 - val_accuracy: 0.7429\n",
            "Epoch 348/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4284 - accuracy: 0.7971 - val_loss: 0.4331 - val_accuracy: 0.7429\n",
            "Epoch 349/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4282 - accuracy: 0.7955 - val_loss: 0.4354 - val_accuracy: 0.7429\n",
            "Epoch 350/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4284 - accuracy: 0.7971 - val_loss: 0.4342 - val_accuracy: 0.7429\n",
            "Epoch 351/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4283 - accuracy: 0.7939 - val_loss: 0.4363 - val_accuracy: 0.7429\n",
            "Epoch 352/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4282 - accuracy: 0.8019 - val_loss: 0.4352 - val_accuracy: 0.7429\n",
            "Epoch 353/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4283 - accuracy: 0.8003 - val_loss: 0.4339 - val_accuracy: 0.7429\n",
            "Epoch 354/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4284 - accuracy: 0.7987 - val_loss: 0.4327 - val_accuracy: 0.7429\n",
            "Epoch 355/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4283 - accuracy: 0.7971 - val_loss: 0.4338 - val_accuracy: 0.7429\n",
            "Epoch 356/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4282 - accuracy: 0.8003 - val_loss: 0.4333 - val_accuracy: 0.7429\n",
            "Epoch 357/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4283 - accuracy: 0.7955 - val_loss: 0.4327 - val_accuracy: 0.7429\n",
            "Epoch 358/750\n",
            "156/156 [==============================] - 0s 3ms/step - loss: 0.4282 - accuracy: 0.7923 - val_loss: 0.4343 - val_accuracy: 0.7429\n",
            "Epoch 359/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4283 - accuracy: 0.7971 - val_loss: 0.4322 - val_accuracy: 0.7429\n",
            "Epoch 360/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4284 - accuracy: 0.7987 - val_loss: 0.4327 - val_accuracy: 0.7429\n",
            "Epoch 361/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4284 - accuracy: 0.8003 - val_loss: 0.4324 - val_accuracy: 0.7429\n",
            "Epoch 362/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4282 - accuracy: 0.7971 - val_loss: 0.4342 - val_accuracy: 0.7429\n",
            "Epoch 363/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4282 - accuracy: 0.7971 - val_loss: 0.4321 - val_accuracy: 0.7429\n",
            "Epoch 364/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4285 - accuracy: 0.7971 - val_loss: 0.4319 - val_accuracy: 0.7429\n",
            "Epoch 365/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4284 - accuracy: 0.7971 - val_loss: 0.4332 - val_accuracy: 0.7429\n",
            "Epoch 366/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4283 - accuracy: 0.7971 - val_loss: 0.4332 - val_accuracy: 0.7429\n",
            "Epoch 367/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4283 - accuracy: 0.7987 - val_loss: 0.4336 - val_accuracy: 0.7429\n",
            "Epoch 368/750\n",
            "156/156 [==============================] - 0s 3ms/step - loss: 0.4282 - accuracy: 0.7971 - val_loss: 0.4357 - val_accuracy: 0.7429\n",
            "Epoch 369/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4282 - accuracy: 0.7939 - val_loss: 0.4365 - val_accuracy: 0.7429\n",
            "Epoch 370/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4279 - accuracy: 0.7955 - val_loss: 0.4315 - val_accuracy: 0.7429\n",
            "Epoch 371/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4280 - accuracy: 0.7971 - val_loss: 0.4297 - val_accuracy: 0.7429\n",
            "Epoch 372/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4283 - accuracy: 0.7955 - val_loss: 0.4323 - val_accuracy: 0.7429\n",
            "Epoch 373/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4283 - accuracy: 0.7971 - val_loss: 0.4360 - val_accuracy: 0.7429\n",
            "Epoch 374/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4282 - accuracy: 0.7971 - val_loss: 0.4321 - val_accuracy: 0.7429\n",
            "Epoch 375/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4282 - accuracy: 0.7971 - val_loss: 0.4358 - val_accuracy: 0.7429\n",
            "Epoch 376/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4281 - accuracy: 0.7987 - val_loss: 0.4329 - val_accuracy: 0.7429\n",
            "Epoch 377/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4283 - accuracy: 0.7987 - val_loss: 0.4340 - val_accuracy: 0.7429\n",
            "Epoch 378/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4283 - accuracy: 0.7971 - val_loss: 0.4331 - val_accuracy: 0.7429\n",
            "Epoch 379/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4283 - accuracy: 0.7987 - val_loss: 0.4336 - val_accuracy: 0.7429\n",
            "Epoch 380/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4280 - accuracy: 0.7971 - val_loss: 0.4358 - val_accuracy: 0.7429\n",
            "Epoch 381/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4282 - accuracy: 0.7971 - val_loss: 0.4342 - val_accuracy: 0.7429\n",
            "Epoch 382/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4280 - accuracy: 0.7987 - val_loss: 0.4332 - val_accuracy: 0.7429\n",
            "Epoch 383/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4282 - accuracy: 0.7955 - val_loss: 0.4340 - val_accuracy: 0.7429\n",
            "Epoch 384/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4282 - accuracy: 0.7971 - val_loss: 0.4353 - val_accuracy: 0.7429\n",
            "Epoch 385/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4282 - accuracy: 0.7955 - val_loss: 0.4353 - val_accuracy: 0.7429\n",
            "Epoch 386/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4281 - accuracy: 0.7987 - val_loss: 0.4324 - val_accuracy: 0.7429\n",
            "Epoch 387/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4282 - accuracy: 0.7987 - val_loss: 0.4336 - val_accuracy: 0.7429\n",
            "Epoch 388/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4280 - accuracy: 0.7939 - val_loss: 0.4346 - val_accuracy: 0.7429\n",
            "Epoch 389/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4280 - accuracy: 0.7955 - val_loss: 0.4355 - val_accuracy: 0.7429\n",
            "Epoch 390/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4282 - accuracy: 0.8003 - val_loss: 0.4350 - val_accuracy: 0.7429\n",
            "Epoch 391/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4282 - accuracy: 0.7971 - val_loss: 0.4348 - val_accuracy: 0.7429\n",
            "Epoch 392/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4281 - accuracy: 0.7971 - val_loss: 0.4334 - val_accuracy: 0.7429\n",
            "Epoch 393/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4280 - accuracy: 0.7971 - val_loss: 0.4348 - val_accuracy: 0.7429\n",
            "Epoch 394/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4281 - accuracy: 0.8003 - val_loss: 0.4328 - val_accuracy: 0.7429\n",
            "Epoch 395/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4281 - accuracy: 0.7987 - val_loss: 0.4333 - val_accuracy: 0.7429\n",
            "Epoch 396/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4280 - accuracy: 0.7987 - val_loss: 0.4347 - val_accuracy: 0.7429\n",
            "Epoch 397/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4280 - accuracy: 0.7971 - val_loss: 0.4336 - val_accuracy: 0.7429\n",
            "Epoch 398/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4279 - accuracy: 0.7987 - val_loss: 0.4322 - val_accuracy: 0.7429\n",
            "Epoch 399/750\n",
            "156/156 [==============================] - 0s 3ms/step - loss: 0.4281 - accuracy: 0.7955 - val_loss: 0.4353 - val_accuracy: 0.7429\n",
            "Epoch 400/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4281 - accuracy: 0.7971 - val_loss: 0.4336 - val_accuracy: 0.7429\n",
            "Epoch 401/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4281 - accuracy: 0.7955 - val_loss: 0.4350 - val_accuracy: 0.7429\n",
            "Epoch 402/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4281 - accuracy: 0.7987 - val_loss: 0.4346 - val_accuracy: 0.7429\n",
            "Epoch 403/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4280 - accuracy: 0.8003 - val_loss: 0.4329 - val_accuracy: 0.7429\n",
            "Epoch 404/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4280 - accuracy: 0.7987 - val_loss: 0.4331 - val_accuracy: 0.7429\n",
            "Epoch 405/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4280 - accuracy: 0.7955 - val_loss: 0.4333 - val_accuracy: 0.7429\n",
            "Epoch 406/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4281 - accuracy: 0.7987 - val_loss: 0.4340 - val_accuracy: 0.7429\n",
            "Epoch 407/750\n",
            "156/156 [==============================] - 0s 3ms/step - loss: 0.4278 - accuracy: 0.7987 - val_loss: 0.4311 - val_accuracy: 0.7429\n",
            "Epoch 408/750\n",
            "156/156 [==============================] - 0s 3ms/step - loss: 0.4280 - accuracy: 0.7923 - val_loss: 0.4338 - val_accuracy: 0.7429\n",
            "Epoch 409/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4281 - accuracy: 0.7955 - val_loss: 0.4344 - val_accuracy: 0.7429\n",
            "Epoch 410/750\n",
            "156/156 [==============================] - 0s 3ms/step - loss: 0.4279 - accuracy: 0.7971 - val_loss: 0.4326 - val_accuracy: 0.7429\n",
            "Epoch 411/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4281 - accuracy: 0.7987 - val_loss: 0.4329 - val_accuracy: 0.7429\n",
            "Epoch 412/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4279 - accuracy: 0.7971 - val_loss: 0.4348 - val_accuracy: 0.7429\n",
            "Epoch 413/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4281 - accuracy: 0.7987 - val_loss: 0.4350 - val_accuracy: 0.7429\n",
            "Epoch 414/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4279 - accuracy: 0.7987 - val_loss: 0.4311 - val_accuracy: 0.7429\n",
            "Epoch 415/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4281 - accuracy: 0.7955 - val_loss: 0.4329 - val_accuracy: 0.7429\n",
            "Epoch 416/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4281 - accuracy: 0.7971 - val_loss: 0.4336 - val_accuracy: 0.7429\n",
            "Epoch 417/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4278 - accuracy: 0.7987 - val_loss: 0.4311 - val_accuracy: 0.7429\n",
            "Epoch 418/750\n",
            "156/156 [==============================] - 0s 3ms/step - loss: 0.4275 - accuracy: 0.7939 - val_loss: 0.4358 - val_accuracy: 0.7429\n",
            "Epoch 419/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4279 - accuracy: 0.7955 - val_loss: 0.4365 - val_accuracy: 0.7429\n",
            "Epoch 420/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4280 - accuracy: 0.7987 - val_loss: 0.4344 - val_accuracy: 0.7429\n",
            "Epoch 421/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4281 - accuracy: 0.7987 - val_loss: 0.4368 - val_accuracy: 0.7429\n",
            "Epoch 422/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4280 - accuracy: 0.7971 - val_loss: 0.4374 - val_accuracy: 0.7429\n",
            "Epoch 423/750\n",
            "156/156 [==============================] - 0s 3ms/step - loss: 0.4281 - accuracy: 0.7971 - val_loss: 0.4360 - val_accuracy: 0.7429\n",
            "Epoch 424/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4280 - accuracy: 0.7971 - val_loss: 0.4344 - val_accuracy: 0.7429\n",
            "Epoch 425/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4278 - accuracy: 0.7971 - val_loss: 0.4323 - val_accuracy: 0.7429\n",
            "Epoch 426/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4280 - accuracy: 0.7971 - val_loss: 0.4322 - val_accuracy: 0.7429\n",
            "Epoch 427/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4280 - accuracy: 0.8003 - val_loss: 0.4361 - val_accuracy: 0.7429\n",
            "Epoch 428/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4278 - accuracy: 0.8003 - val_loss: 0.4360 - val_accuracy: 0.7429\n",
            "Epoch 429/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4276 - accuracy: 0.7939 - val_loss: 0.4304 - val_accuracy: 0.7429\n",
            "Epoch 430/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4280 - accuracy: 0.7971 - val_loss: 0.4339 - val_accuracy: 0.7429\n",
            "Epoch 431/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4280 - accuracy: 0.7971 - val_loss: 0.4344 - val_accuracy: 0.7429\n",
            "Epoch 432/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4280 - accuracy: 0.7987 - val_loss: 0.4325 - val_accuracy: 0.7429\n",
            "Epoch 433/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4280 - accuracy: 0.7987 - val_loss: 0.4324 - val_accuracy: 0.7429\n",
            "Epoch 434/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4279 - accuracy: 0.7987 - val_loss: 0.4347 - val_accuracy: 0.7429\n",
            "Epoch 435/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4279 - accuracy: 0.7971 - val_loss: 0.4334 - val_accuracy: 0.7429\n",
            "Epoch 436/750\n",
            "156/156 [==============================] - 0s 3ms/step - loss: 0.4278 - accuracy: 0.7971 - val_loss: 0.4330 - val_accuracy: 0.7429\n",
            "Epoch 437/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4279 - accuracy: 0.7955 - val_loss: 0.4349 - val_accuracy: 0.7429\n",
            "Epoch 438/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4277 - accuracy: 0.7971 - val_loss: 0.4322 - val_accuracy: 0.7429\n",
            "Epoch 439/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4277 - accuracy: 0.7971 - val_loss: 0.4328 - val_accuracy: 0.7429\n",
            "Epoch 440/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4280 - accuracy: 0.7971 - val_loss: 0.4338 - val_accuracy: 0.7429\n",
            "Epoch 441/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4279 - accuracy: 0.7987 - val_loss: 0.4335 - val_accuracy: 0.7429\n",
            "Epoch 442/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4278 - accuracy: 0.7939 - val_loss: 0.4350 - val_accuracy: 0.7429\n",
            "Epoch 443/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4277 - accuracy: 0.7971 - val_loss: 0.4327 - val_accuracy: 0.7429\n",
            "Epoch 444/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4278 - accuracy: 0.7955 - val_loss: 0.4346 - val_accuracy: 0.7429\n",
            "Epoch 445/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4279 - accuracy: 0.7987 - val_loss: 0.4335 - val_accuracy: 0.7429\n",
            "Epoch 446/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4278 - accuracy: 0.7971 - val_loss: 0.4370 - val_accuracy: 0.7429\n",
            "Epoch 447/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4280 - accuracy: 0.7987 - val_loss: 0.4360 - val_accuracy: 0.7429\n",
            "Epoch 448/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4277 - accuracy: 0.7987 - val_loss: 0.4363 - val_accuracy: 0.7429\n",
            "Epoch 449/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4279 - accuracy: 0.7971 - val_loss: 0.4350 - val_accuracy: 0.7429\n",
            "Epoch 450/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4278 - accuracy: 0.7971 - val_loss: 0.4341 - val_accuracy: 0.7429\n",
            "Epoch 451/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4277 - accuracy: 0.7971 - val_loss: 0.4313 - val_accuracy: 0.7429\n",
            "Epoch 452/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4278 - accuracy: 0.7987 - val_loss: 0.4308 - val_accuracy: 0.7429\n",
            "Epoch 453/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4280 - accuracy: 0.7939 - val_loss: 0.4328 - val_accuracy: 0.7429\n",
            "Epoch 454/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4278 - accuracy: 0.7971 - val_loss: 0.4319 - val_accuracy: 0.7429\n",
            "Epoch 455/750\n",
            "156/156 [==============================] - 0s 3ms/step - loss: 0.4276 - accuracy: 0.7955 - val_loss: 0.4343 - val_accuracy: 0.7429\n",
            "Epoch 456/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4278 - accuracy: 0.7987 - val_loss: 0.4348 - val_accuracy: 0.7429\n",
            "Epoch 457/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4278 - accuracy: 0.7971 - val_loss: 0.4346 - val_accuracy: 0.7429\n",
            "Epoch 458/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4277 - accuracy: 0.7955 - val_loss: 0.4354 - val_accuracy: 0.7429\n",
            "Epoch 459/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4278 - accuracy: 0.7955 - val_loss: 0.4333 - val_accuracy: 0.7429\n",
            "Epoch 460/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4278 - accuracy: 0.7987 - val_loss: 0.4335 - val_accuracy: 0.7429\n",
            "Epoch 461/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4277 - accuracy: 0.7971 - val_loss: 0.4317 - val_accuracy: 0.7429\n",
            "Epoch 462/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4278 - accuracy: 0.7955 - val_loss: 0.4326 - val_accuracy: 0.7429\n",
            "Epoch 463/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4278 - accuracy: 0.7955 - val_loss: 0.4310 - val_accuracy: 0.7429\n",
            "Epoch 464/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4277 - accuracy: 0.7939 - val_loss: 0.4340 - val_accuracy: 0.7429\n",
            "Epoch 465/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4275 - accuracy: 0.7971 - val_loss: 0.4322 - val_accuracy: 0.7429\n",
            "Epoch 466/750\n",
            "156/156 [==============================] - 0s 3ms/step - loss: 0.4278 - accuracy: 0.7987 - val_loss: 0.4324 - val_accuracy: 0.7429\n",
            "Epoch 467/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4278 - accuracy: 0.7987 - val_loss: 0.4315 - val_accuracy: 0.7429\n",
            "Epoch 468/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4277 - accuracy: 0.7955 - val_loss: 0.4346 - val_accuracy: 0.7429\n",
            "Epoch 469/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4276 - accuracy: 0.7971 - val_loss: 0.4360 - val_accuracy: 0.7429\n",
            "Epoch 470/750\n",
            "156/156 [==============================] - 0s 3ms/step - loss: 0.4275 - accuracy: 0.8003 - val_loss: 0.4390 - val_accuracy: 0.7429\n",
            "Epoch 471/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4278 - accuracy: 0.7939 - val_loss: 0.4343 - val_accuracy: 0.7429\n",
            "Epoch 472/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4276 - accuracy: 0.7971 - val_loss: 0.4329 - val_accuracy: 0.7429\n",
            "Epoch 473/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4278 - accuracy: 0.7939 - val_loss: 0.4341 - val_accuracy: 0.7429\n",
            "Epoch 474/750\n",
            "156/156 [==============================] - 0s 3ms/step - loss: 0.4277 - accuracy: 0.7971 - val_loss: 0.4346 - val_accuracy: 0.7429\n",
            "Epoch 475/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4276 - accuracy: 0.7971 - val_loss: 0.4356 - val_accuracy: 0.7429\n",
            "Epoch 476/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4278 - accuracy: 0.7955 - val_loss: 0.4365 - val_accuracy: 0.7429\n",
            "Epoch 477/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4279 - accuracy: 0.7971 - val_loss: 0.4360 - val_accuracy: 0.7429\n",
            "Epoch 478/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4277 - accuracy: 0.7955 - val_loss: 0.4351 - val_accuracy: 0.7429\n",
            "Epoch 479/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4276 - accuracy: 0.7939 - val_loss: 0.4342 - val_accuracy: 0.7429\n",
            "Epoch 480/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4277 - accuracy: 0.8003 - val_loss: 0.4348 - val_accuracy: 0.7429\n",
            "Epoch 481/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4276 - accuracy: 0.7939 - val_loss: 0.4373 - val_accuracy: 0.7429\n",
            "Epoch 482/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4277 - accuracy: 0.7939 - val_loss: 0.4351 - val_accuracy: 0.7429\n",
            "Epoch 483/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4276 - accuracy: 0.7939 - val_loss: 0.4361 - val_accuracy: 0.7429\n",
            "Epoch 484/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4277 - accuracy: 0.7955 - val_loss: 0.4346 - val_accuracy: 0.7429\n",
            "Epoch 485/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4277 - accuracy: 0.7971 - val_loss: 0.4317 - val_accuracy: 0.7429\n",
            "Epoch 486/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4277 - accuracy: 0.7987 - val_loss: 0.4339 - val_accuracy: 0.7429\n",
            "Epoch 487/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4276 - accuracy: 0.7987 - val_loss: 0.4351 - val_accuracy: 0.7429\n",
            "Epoch 488/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4275 - accuracy: 0.7987 - val_loss: 0.4353 - val_accuracy: 0.7429\n",
            "Epoch 489/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4275 - accuracy: 0.7955 - val_loss: 0.4324 - val_accuracy: 0.7429\n",
            "Epoch 490/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4275 - accuracy: 0.8019 - val_loss: 0.4304 - val_accuracy: 0.7429\n",
            "Epoch 491/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4277 - accuracy: 0.7971 - val_loss: 0.4317 - val_accuracy: 0.7429\n",
            "Epoch 492/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4276 - accuracy: 0.8035 - val_loss: 0.4321 - val_accuracy: 0.7429\n",
            "Epoch 493/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4275 - accuracy: 0.8003 - val_loss: 0.4341 - val_accuracy: 0.7429\n",
            "Epoch 494/750\n",
            "156/156 [==============================] - 0s 3ms/step - loss: 0.4278 - accuracy: 0.7971 - val_loss: 0.4324 - val_accuracy: 0.7429\n",
            "Epoch 495/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4276 - accuracy: 0.7971 - val_loss: 0.4319 - val_accuracy: 0.7429\n",
            "Epoch 496/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4275 - accuracy: 0.7939 - val_loss: 0.4319 - val_accuracy: 0.7429\n",
            "Epoch 497/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4276 - accuracy: 0.7971 - val_loss: 0.4343 - val_accuracy: 0.7429\n",
            "Epoch 498/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4276 - accuracy: 0.7955 - val_loss: 0.4348 - val_accuracy: 0.7429\n",
            "Epoch 499/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4272 - accuracy: 0.7955 - val_loss: 0.4316 - val_accuracy: 0.7429\n",
            "Epoch 500/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4275 - accuracy: 0.8019 - val_loss: 0.4339 - val_accuracy: 0.7429\n",
            "Epoch 501/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4276 - accuracy: 0.7971 - val_loss: 0.4346 - val_accuracy: 0.7429\n",
            "Epoch 502/750\n",
            "156/156 [==============================] - 0s 3ms/step - loss: 0.4275 - accuracy: 0.7939 - val_loss: 0.4349 - val_accuracy: 0.7429\n",
            "Epoch 503/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4276 - accuracy: 0.7955 - val_loss: 0.4362 - val_accuracy: 0.7429\n",
            "Epoch 504/750\n",
            "156/156 [==============================] - 0s 3ms/step - loss: 0.4275 - accuracy: 0.7955 - val_loss: 0.4333 - val_accuracy: 0.7429\n",
            "Epoch 505/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4276 - accuracy: 0.7987 - val_loss: 0.4323 - val_accuracy: 0.7429\n",
            "Epoch 506/750\n",
            "156/156 [==============================] - 0s 3ms/step - loss: 0.4276 - accuracy: 0.7923 - val_loss: 0.4336 - val_accuracy: 0.7429\n",
            "Epoch 507/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4275 - accuracy: 0.7955 - val_loss: 0.4317 - val_accuracy: 0.7429\n",
            "Epoch 508/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4275 - accuracy: 0.7987 - val_loss: 0.4346 - val_accuracy: 0.7429\n",
            "Epoch 509/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4277 - accuracy: 0.7971 - val_loss: 0.4344 - val_accuracy: 0.7429\n",
            "Epoch 510/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4273 - accuracy: 0.7955 - val_loss: 0.4368 - val_accuracy: 0.7429\n",
            "Epoch 511/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4274 - accuracy: 0.7971 - val_loss: 0.4336 - val_accuracy: 0.7429\n",
            "Epoch 512/750\n",
            "156/156 [==============================] - 0s 3ms/step - loss: 0.4276 - accuracy: 0.8019 - val_loss: 0.4348 - val_accuracy: 0.7429\n",
            "Epoch 513/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4276 - accuracy: 0.7955 - val_loss: 0.4323 - val_accuracy: 0.7429\n",
            "Epoch 514/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4274 - accuracy: 0.7955 - val_loss: 0.4330 - val_accuracy: 0.7429\n",
            "Epoch 515/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4274 - accuracy: 0.7939 - val_loss: 0.4319 - val_accuracy: 0.7429\n",
            "Epoch 516/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4274 - accuracy: 0.7971 - val_loss: 0.4340 - val_accuracy: 0.7429\n",
            "Epoch 517/750\n",
            "156/156 [==============================] - 0s 3ms/step - loss: 0.4275 - accuracy: 0.7971 - val_loss: 0.4319 - val_accuracy: 0.7429\n",
            "Epoch 518/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4276 - accuracy: 0.7987 - val_loss: 0.4332 - val_accuracy: 0.7429\n",
            "Epoch 519/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4275 - accuracy: 0.7955 - val_loss: 0.4340 - val_accuracy: 0.7429\n",
            "Epoch 520/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4274 - accuracy: 0.7955 - val_loss: 0.4343 - val_accuracy: 0.7429\n",
            "Epoch 521/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4270 - accuracy: 0.7939 - val_loss: 0.4315 - val_accuracy: 0.7429\n",
            "Epoch 522/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4276 - accuracy: 0.8019 - val_loss: 0.4334 - val_accuracy: 0.7429\n",
            "Epoch 523/750\n",
            "156/156 [==============================] - 0s 3ms/step - loss: 0.4272 - accuracy: 0.7971 - val_loss: 0.4366 - val_accuracy: 0.7429\n",
            "Epoch 524/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4275 - accuracy: 0.7955 - val_loss: 0.4372 - val_accuracy: 0.7429\n",
            "Epoch 525/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4274 - accuracy: 0.7971 - val_loss: 0.4352 - val_accuracy: 0.7429\n",
            "Epoch 526/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4272 - accuracy: 0.7955 - val_loss: 0.4307 - val_accuracy: 0.7429\n",
            "Epoch 527/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4271 - accuracy: 0.7955 - val_loss: 0.4297 - val_accuracy: 0.7429\n",
            "Epoch 528/750\n",
            "156/156 [==============================] - 0s 3ms/step - loss: 0.4275 - accuracy: 0.8003 - val_loss: 0.4308 - val_accuracy: 0.7429\n",
            "Epoch 529/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4271 - accuracy: 0.7971 - val_loss: 0.4338 - val_accuracy: 0.7429\n",
            "Epoch 530/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4274 - accuracy: 0.7987 - val_loss: 0.4334 - val_accuracy: 0.7429\n",
            "Epoch 531/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4272 - accuracy: 0.8019 - val_loss: 0.4333 - val_accuracy: 0.7429\n",
            "Epoch 532/750\n",
            "156/156 [==============================] - 0s 3ms/step - loss: 0.4272 - accuracy: 0.7971 - val_loss: 0.4368 - val_accuracy: 0.7429\n",
            "Epoch 533/750\n",
            "156/156 [==============================] - 0s 3ms/step - loss: 0.4274 - accuracy: 0.7987 - val_loss: 0.4345 - val_accuracy: 0.7429\n",
            "Epoch 534/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4274 - accuracy: 0.7987 - val_loss: 0.4344 - val_accuracy: 0.7429\n",
            "Epoch 535/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4271 - accuracy: 0.7955 - val_loss: 0.4392 - val_accuracy: 0.7429\n",
            "Epoch 536/750\n",
            "156/156 [==============================] - 0s 3ms/step - loss: 0.4274 - accuracy: 0.7955 - val_loss: 0.4356 - val_accuracy: 0.7429\n",
            "Epoch 537/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4272 - accuracy: 0.8003 - val_loss: 0.4374 - val_accuracy: 0.7429\n",
            "Epoch 538/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4274 - accuracy: 0.7971 - val_loss: 0.4357 - val_accuracy: 0.7429\n",
            "Epoch 539/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4273 - accuracy: 0.7955 - val_loss: 0.4365 - val_accuracy: 0.7429\n",
            "Epoch 540/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4273 - accuracy: 0.7971 - val_loss: 0.4359 - val_accuracy: 0.7429\n",
            "Epoch 541/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4272 - accuracy: 0.7987 - val_loss: 0.4375 - val_accuracy: 0.7429\n",
            "Epoch 542/750\n",
            "156/156 [==============================] - 0s 3ms/step - loss: 0.4273 - accuracy: 0.7955 - val_loss: 0.4347 - val_accuracy: 0.7429\n",
            "Epoch 543/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4272 - accuracy: 0.7955 - val_loss: 0.4361 - val_accuracy: 0.7429\n",
            "Epoch 544/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4275 - accuracy: 0.7955 - val_loss: 0.4348 - val_accuracy: 0.7429\n",
            "Epoch 545/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4271 - accuracy: 0.7955 - val_loss: 0.4334 - val_accuracy: 0.7429\n",
            "Epoch 546/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4271 - accuracy: 0.7923 - val_loss: 0.4372 - val_accuracy: 0.7429\n",
            "Epoch 547/750\n",
            "156/156 [==============================] - 0s 3ms/step - loss: 0.4270 - accuracy: 0.8003 - val_loss: 0.4365 - val_accuracy: 0.7429\n",
            "Epoch 548/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4274 - accuracy: 0.7955 - val_loss: 0.4339 - val_accuracy: 0.7429\n",
            "Epoch 549/750\n",
            "156/156 [==============================] - 0s 3ms/step - loss: 0.4273 - accuracy: 0.7987 - val_loss: 0.4329 - val_accuracy: 0.7429\n",
            "Epoch 550/750\n",
            "156/156 [==============================] - 0s 3ms/step - loss: 0.4272 - accuracy: 0.7955 - val_loss: 0.4348 - val_accuracy: 0.7429\n",
            "Epoch 551/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4274 - accuracy: 0.7987 - val_loss: 0.4345 - val_accuracy: 0.7429\n",
            "Epoch 552/750\n",
            "156/156 [==============================] - 0s 3ms/step - loss: 0.4270 - accuracy: 0.7955 - val_loss: 0.4375 - val_accuracy: 0.7429\n",
            "Epoch 553/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4275 - accuracy: 0.7971 - val_loss: 0.4400 - val_accuracy: 0.7429\n",
            "Epoch 554/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4270 - accuracy: 0.7923 - val_loss: 0.4334 - val_accuracy: 0.7429\n",
            "Epoch 555/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4268 - accuracy: 0.7923 - val_loss: 0.4311 - val_accuracy: 0.7429\n",
            "Epoch 556/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4272 - accuracy: 0.7971 - val_loss: 0.4305 - val_accuracy: 0.7429\n",
            "Epoch 557/750\n",
            "156/156 [==============================] - 0s 3ms/step - loss: 0.4274 - accuracy: 0.8003 - val_loss: 0.4317 - val_accuracy: 0.7429\n",
            "Epoch 558/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4273 - accuracy: 0.7955 - val_loss: 0.4326 - val_accuracy: 0.7429\n",
            "Epoch 559/750\n",
            "156/156 [==============================] - 0s 3ms/step - loss: 0.4272 - accuracy: 0.7971 - val_loss: 0.4347 - val_accuracy: 0.7429\n",
            "Epoch 560/750\n",
            "156/156 [==============================] - 0s 3ms/step - loss: 0.4272 - accuracy: 0.7971 - val_loss: 0.4366 - val_accuracy: 0.7429\n",
            "Epoch 561/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4270 - accuracy: 0.7955 - val_loss: 0.4345 - val_accuracy: 0.7429\n",
            "Epoch 562/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4270 - accuracy: 0.8003 - val_loss: 0.4357 - val_accuracy: 0.7429\n",
            "Epoch 563/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4271 - accuracy: 0.7955 - val_loss: 0.4339 - val_accuracy: 0.7429\n",
            "Epoch 564/750\n",
            "156/156 [==============================] - 0s 3ms/step - loss: 0.4272 - accuracy: 0.7987 - val_loss: 0.4395 - val_accuracy: 0.7429\n",
            "Epoch 565/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4271 - accuracy: 0.7955 - val_loss: 0.4358 - val_accuracy: 0.7429\n",
            "Epoch 566/750\n",
            "156/156 [==============================] - 0s 3ms/step - loss: 0.4270 - accuracy: 0.7971 - val_loss: 0.4376 - val_accuracy: 0.7429\n",
            "Epoch 567/750\n",
            "156/156 [==============================] - 0s 3ms/step - loss: 0.4272 - accuracy: 0.7955 - val_loss: 0.4372 - val_accuracy: 0.7429\n",
            "Epoch 568/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4271 - accuracy: 0.7955 - val_loss: 0.4347 - val_accuracy: 0.7429\n",
            "Epoch 569/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4273 - accuracy: 0.7971 - val_loss: 0.4369 - val_accuracy: 0.7429\n",
            "Epoch 570/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4272 - accuracy: 0.7939 - val_loss: 0.4371 - val_accuracy: 0.7429\n",
            "Epoch 571/750\n",
            "156/156 [==============================] - 0s 3ms/step - loss: 0.4271 - accuracy: 0.7971 - val_loss: 0.4383 - val_accuracy: 0.7429\n",
            "Epoch 572/750\n",
            "156/156 [==============================] - 0s 3ms/step - loss: 0.4272 - accuracy: 0.8003 - val_loss: 0.4357 - val_accuracy: 0.7429\n",
            "Epoch 573/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4272 - accuracy: 0.7987 - val_loss: 0.4357 - val_accuracy: 0.7429\n",
            "Epoch 574/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4271 - accuracy: 0.7971 - val_loss: 0.4340 - val_accuracy: 0.7429\n",
            "Epoch 575/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4270 - accuracy: 0.7939 - val_loss: 0.4344 - val_accuracy: 0.7429\n",
            "Epoch 576/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4269 - accuracy: 0.7971 - val_loss: 0.4383 - val_accuracy: 0.7429\n",
            "Epoch 577/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4271 - accuracy: 0.7971 - val_loss: 0.4358 - val_accuracy: 0.7429\n",
            "Epoch 578/750\n",
            "156/156 [==============================] - 0s 3ms/step - loss: 0.4272 - accuracy: 0.7939 - val_loss: 0.4342 - val_accuracy: 0.7429\n",
            "Epoch 579/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4272 - accuracy: 0.8003 - val_loss: 0.4375 - val_accuracy: 0.7429\n",
            "Epoch 580/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4271 - accuracy: 0.7987 - val_loss: 0.4379 - val_accuracy: 0.7429\n",
            "Epoch 581/750\n",
            "156/156 [==============================] - 0s 3ms/step - loss: 0.4271 - accuracy: 0.7939 - val_loss: 0.4357 - val_accuracy: 0.7429\n",
            "Epoch 582/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4271 - accuracy: 0.7955 - val_loss: 0.4362 - val_accuracy: 0.7429\n",
            "Epoch 583/750\n",
            "156/156 [==============================] - 0s 3ms/step - loss: 0.4269 - accuracy: 0.8003 - val_loss: 0.4380 - val_accuracy: 0.7429\n",
            "Epoch 584/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4271 - accuracy: 0.7955 - val_loss: 0.4378 - val_accuracy: 0.7429\n",
            "Epoch 585/750\n",
            "156/156 [==============================] - 0s 3ms/step - loss: 0.4271 - accuracy: 0.7939 - val_loss: 0.4343 - val_accuracy: 0.7429\n",
            "Epoch 586/750\n",
            "156/156 [==============================] - 0s 3ms/step - loss: 0.4271 - accuracy: 0.7939 - val_loss: 0.4367 - val_accuracy: 0.7429\n",
            "Epoch 587/750\n",
            "156/156 [==============================] - 0s 3ms/step - loss: 0.4270 - accuracy: 0.7955 - val_loss: 0.4354 - val_accuracy: 0.7429\n",
            "Epoch 588/750\n",
            "156/156 [==============================] - 0s 3ms/step - loss: 0.4265 - accuracy: 0.7955 - val_loss: 0.4316 - val_accuracy: 0.7429\n",
            "Epoch 589/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4271 - accuracy: 0.7923 - val_loss: 0.4334 - val_accuracy: 0.7429\n",
            "Epoch 590/750\n",
            "156/156 [==============================] - 0s 3ms/step - loss: 0.4269 - accuracy: 0.7971 - val_loss: 0.4371 - val_accuracy: 0.7429\n",
            "Epoch 591/750\n",
            "156/156 [==============================] - 0s 3ms/step - loss: 0.4271 - accuracy: 0.7955 - val_loss: 0.4351 - val_accuracy: 0.7429\n",
            "Epoch 592/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4269 - accuracy: 0.8003 - val_loss: 0.4374 - val_accuracy: 0.7429\n",
            "Epoch 593/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4270 - accuracy: 0.7971 - val_loss: 0.4372 - val_accuracy: 0.7429\n",
            "Epoch 594/750\n",
            "156/156 [==============================] - 0s 3ms/step - loss: 0.4268 - accuracy: 0.7939 - val_loss: 0.4341 - val_accuracy: 0.7429\n",
            "Epoch 595/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4271 - accuracy: 0.7939 - val_loss: 0.4357 - val_accuracy: 0.7429\n",
            "Epoch 596/750\n",
            "156/156 [==============================] - 0s 3ms/step - loss: 0.4270 - accuracy: 0.7955 - val_loss: 0.4340 - val_accuracy: 0.7429\n",
            "Epoch 597/750\n",
            "156/156 [==============================] - 0s 3ms/step - loss: 0.4268 - accuracy: 0.8003 - val_loss: 0.4326 - val_accuracy: 0.7429\n",
            "Epoch 598/750\n",
            "156/156 [==============================] - 0s 3ms/step - loss: 0.4271 - accuracy: 0.7987 - val_loss: 0.4340 - val_accuracy: 0.7429\n",
            "Epoch 599/750\n",
            "156/156 [==============================] - 0s 3ms/step - loss: 0.4270 - accuracy: 0.7987 - val_loss: 0.4381 - val_accuracy: 0.7429\n",
            "Epoch 600/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4270 - accuracy: 0.7971 - val_loss: 0.4373 - val_accuracy: 0.7429\n",
            "Epoch 601/750\n",
            "156/156 [==============================] - 0s 3ms/step - loss: 0.4271 - accuracy: 0.8019 - val_loss: 0.4353 - val_accuracy: 0.7429\n",
            "Epoch 602/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4268 - accuracy: 0.7971 - val_loss: 0.4377 - val_accuracy: 0.7429\n",
            "Epoch 603/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4268 - accuracy: 0.8003 - val_loss: 0.4345 - val_accuracy: 0.7429\n",
            "Epoch 604/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4268 - accuracy: 0.7955 - val_loss: 0.4381 - val_accuracy: 0.7429\n",
            "Epoch 605/750\n",
            "156/156 [==============================] - 0s 3ms/step - loss: 0.4271 - accuracy: 0.7939 - val_loss: 0.4369 - val_accuracy: 0.7429\n",
            "Epoch 606/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4269 - accuracy: 0.8003 - val_loss: 0.4359 - val_accuracy: 0.7429\n",
            "Epoch 607/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4270 - accuracy: 0.7939 - val_loss: 0.4379 - val_accuracy: 0.7429\n",
            "Epoch 608/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4271 - accuracy: 0.7955 - val_loss: 0.4357 - val_accuracy: 0.7429\n",
            "Epoch 609/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4268 - accuracy: 0.7955 - val_loss: 0.4352 - val_accuracy: 0.7429\n",
            "Epoch 610/750\n",
            "156/156 [==============================] - 0s 3ms/step - loss: 0.4269 - accuracy: 0.7971 - val_loss: 0.4340 - val_accuracy: 0.7429\n",
            "Epoch 611/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4271 - accuracy: 0.7955 - val_loss: 0.4340 - val_accuracy: 0.7429\n",
            "Epoch 612/750\n",
            "156/156 [==============================] - 0s 3ms/step - loss: 0.4270 - accuracy: 0.7971 - val_loss: 0.4358 - val_accuracy: 0.7429\n",
            "Epoch 613/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4269 - accuracy: 0.7955 - val_loss: 0.4352 - val_accuracy: 0.7429\n",
            "Epoch 614/750\n",
            "156/156 [==============================] - 0s 3ms/step - loss: 0.4269 - accuracy: 0.7987 - val_loss: 0.4369 - val_accuracy: 0.7429\n",
            "Epoch 615/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4270 - accuracy: 0.7955 - val_loss: 0.4343 - val_accuracy: 0.7429\n",
            "Epoch 616/750\n",
            "156/156 [==============================] - 0s 3ms/step - loss: 0.4269 - accuracy: 0.7987 - val_loss: 0.4340 - val_accuracy: 0.7429\n",
            "Epoch 617/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4267 - accuracy: 0.7971 - val_loss: 0.4355 - val_accuracy: 0.7429\n",
            "Epoch 618/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4268 - accuracy: 0.7987 - val_loss: 0.4380 - val_accuracy: 0.7429\n",
            "Epoch 619/750\n",
            "156/156 [==============================] - 0s 3ms/step - loss: 0.4268 - accuracy: 0.8003 - val_loss: 0.4377 - val_accuracy: 0.7429\n",
            "Epoch 620/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4270 - accuracy: 0.7971 - val_loss: 0.4351 - val_accuracy: 0.7429\n",
            "Epoch 621/750\n",
            "156/156 [==============================] - 0s 3ms/step - loss: 0.4269 - accuracy: 0.7939 - val_loss: 0.4364 - val_accuracy: 0.7429\n",
            "Epoch 622/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4268 - accuracy: 0.7971 - val_loss: 0.4362 - val_accuracy: 0.7429\n",
            "Epoch 623/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4268 - accuracy: 0.7939 - val_loss: 0.4345 - val_accuracy: 0.7429\n",
            "Epoch 624/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4269 - accuracy: 0.7955 - val_loss: 0.4386 - val_accuracy: 0.7429\n",
            "Epoch 625/750\n",
            "156/156 [==============================] - 0s 3ms/step - loss: 0.4269 - accuracy: 0.7939 - val_loss: 0.4371 - val_accuracy: 0.7429\n",
            "Epoch 626/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4267 - accuracy: 0.7971 - val_loss: 0.4359 - val_accuracy: 0.7429\n",
            "Epoch 627/750\n",
            "156/156 [==============================] - 0s 3ms/step - loss: 0.4267 - accuracy: 0.7955 - val_loss: 0.4335 - val_accuracy: 0.7429\n",
            "Epoch 628/750\n",
            "156/156 [==============================] - 0s 3ms/step - loss: 0.4268 - accuracy: 0.7987 - val_loss: 0.4370 - val_accuracy: 0.7429\n",
            "Epoch 629/750\n",
            "156/156 [==============================] - 0s 3ms/step - loss: 0.4268 - accuracy: 0.7971 - val_loss: 0.4382 - val_accuracy: 0.7429\n",
            "Epoch 630/750\n",
            "156/156 [==============================] - 0s 3ms/step - loss: 0.4268 - accuracy: 0.7939 - val_loss: 0.4361 - val_accuracy: 0.7429\n",
            "Epoch 631/750\n",
            "156/156 [==============================] - 0s 3ms/step - loss: 0.4267 - accuracy: 0.7987 - val_loss: 0.4395 - val_accuracy: 0.7429\n",
            "Epoch 632/750\n",
            "156/156 [==============================] - 0s 3ms/step - loss: 0.4269 - accuracy: 0.7955 - val_loss: 0.4376 - val_accuracy: 0.7429\n",
            "Epoch 633/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4269 - accuracy: 0.7939 - val_loss: 0.4353 - val_accuracy: 0.7429\n",
            "Epoch 634/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4267 - accuracy: 0.7971 - val_loss: 0.4323 - val_accuracy: 0.7429\n",
            "Epoch 635/750\n",
            "156/156 [==============================] - 0s 3ms/step - loss: 0.4269 - accuracy: 0.7987 - val_loss: 0.4347 - val_accuracy: 0.7429\n",
            "Epoch 636/750\n",
            "156/156 [==============================] - 0s 3ms/step - loss: 0.4270 - accuracy: 0.7955 - val_loss: 0.4352 - val_accuracy: 0.7429\n",
            "Epoch 637/750\n",
            "156/156 [==============================] - 0s 3ms/step - loss: 0.4266 - accuracy: 0.8003 - val_loss: 0.4404 - val_accuracy: 0.7429\n",
            "Epoch 638/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4269 - accuracy: 0.7939 - val_loss: 0.4368 - val_accuracy: 0.7429\n",
            "Epoch 639/750\n",
            "156/156 [==============================] - 0s 3ms/step - loss: 0.4267 - accuracy: 0.8003 - val_loss: 0.4379 - val_accuracy: 0.7429\n",
            "Epoch 640/750\n",
            "156/156 [==============================] - 0s 3ms/step - loss: 0.4267 - accuracy: 0.7987 - val_loss: 0.4372 - val_accuracy: 0.7429\n",
            "Epoch 641/750\n",
            "156/156 [==============================] - 0s 3ms/step - loss: 0.4268 - accuracy: 0.7939 - val_loss: 0.4357 - val_accuracy: 0.7429\n",
            "Epoch 642/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4267 - accuracy: 0.7971 - val_loss: 0.4362 - val_accuracy: 0.7429\n",
            "Epoch 643/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4268 - accuracy: 0.7987 - val_loss: 0.4361 - val_accuracy: 0.7429\n",
            "Epoch 644/750\n",
            "156/156 [==============================] - 0s 3ms/step - loss: 0.4268 - accuracy: 0.7971 - val_loss: 0.4366 - val_accuracy: 0.7429\n",
            "Epoch 645/750\n",
            "156/156 [==============================] - 0s 3ms/step - loss: 0.4267 - accuracy: 0.7971 - val_loss: 0.4385 - val_accuracy: 0.7429\n",
            "Epoch 646/750\n",
            "156/156 [==============================] - 0s 3ms/step - loss: 0.4266 - accuracy: 0.8003 - val_loss: 0.4356 - val_accuracy: 0.7429\n",
            "Epoch 647/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4265 - accuracy: 0.7955 - val_loss: 0.4392 - val_accuracy: 0.7429\n",
            "Epoch 648/750\n",
            "156/156 [==============================] - 0s 3ms/step - loss: 0.4267 - accuracy: 0.7939 - val_loss: 0.4384 - val_accuracy: 0.7429\n",
            "Epoch 649/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4267 - accuracy: 0.7971 - val_loss: 0.4368 - val_accuracy: 0.7429\n",
            "Epoch 650/750\n",
            "156/156 [==============================] - 0s 3ms/step - loss: 0.4266 - accuracy: 0.7971 - val_loss: 0.4354 - val_accuracy: 0.7429\n",
            "Epoch 651/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4266 - accuracy: 0.7939 - val_loss: 0.4357 - val_accuracy: 0.7429\n",
            "Epoch 652/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4262 - accuracy: 0.7923 - val_loss: 0.4405 - val_accuracy: 0.7429\n",
            "Epoch 653/750\n",
            "156/156 [==============================] - 0s 3ms/step - loss: 0.4263 - accuracy: 0.7907 - val_loss: 0.4331 - val_accuracy: 0.7429\n",
            "Epoch 654/750\n",
            "156/156 [==============================] - 0s 3ms/step - loss: 0.4267 - accuracy: 0.7955 - val_loss: 0.4320 - val_accuracy: 0.7429\n",
            "Epoch 655/750\n",
            "156/156 [==============================] - 0s 3ms/step - loss: 0.4270 - accuracy: 0.8003 - val_loss: 0.4351 - val_accuracy: 0.7429\n",
            "Epoch 656/750\n",
            "156/156 [==============================] - 0s 3ms/step - loss: 0.4267 - accuracy: 0.7971 - val_loss: 0.4319 - val_accuracy: 0.7429\n",
            "Epoch 657/750\n",
            "156/156 [==============================] - 0s 3ms/step - loss: 0.4269 - accuracy: 0.7939 - val_loss: 0.4357 - val_accuracy: 0.7429\n",
            "Epoch 658/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4267 - accuracy: 0.7955 - val_loss: 0.4380 - val_accuracy: 0.7429\n",
            "Epoch 659/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4267 - accuracy: 0.7955 - val_loss: 0.4378 - val_accuracy: 0.7429\n",
            "Epoch 660/750\n",
            "156/156 [==============================] - 0s 3ms/step - loss: 0.4268 - accuracy: 0.7987 - val_loss: 0.4359 - val_accuracy: 0.7429\n",
            "Epoch 661/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4266 - accuracy: 0.7955 - val_loss: 0.4335 - val_accuracy: 0.7429\n",
            "Epoch 662/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4266 - accuracy: 0.7987 - val_loss: 0.4357 - val_accuracy: 0.7429\n",
            "Epoch 663/750\n",
            "156/156 [==============================] - 0s 3ms/step - loss: 0.4266 - accuracy: 0.7971 - val_loss: 0.4350 - val_accuracy: 0.7429\n",
            "Epoch 664/750\n",
            "156/156 [==============================] - 0s 3ms/step - loss: 0.4267 - accuracy: 0.8003 - val_loss: 0.4359 - val_accuracy: 0.7429\n",
            "Epoch 665/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4266 - accuracy: 0.7971 - val_loss: 0.4338 - val_accuracy: 0.7429\n",
            "Epoch 666/750\n",
            "156/156 [==============================] - 0s 3ms/step - loss: 0.4267 - accuracy: 0.7971 - val_loss: 0.4341 - val_accuracy: 0.7429\n",
            "Epoch 667/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4265 - accuracy: 0.7987 - val_loss: 0.4378 - val_accuracy: 0.7429\n",
            "Epoch 668/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4266 - accuracy: 0.8003 - val_loss: 0.4347 - val_accuracy: 0.7429\n",
            "Epoch 669/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4267 - accuracy: 0.7955 - val_loss: 0.4358 - val_accuracy: 0.7429\n",
            "Epoch 670/750\n",
            "156/156 [==============================] - 0s 3ms/step - loss: 0.4264 - accuracy: 0.7987 - val_loss: 0.4381 - val_accuracy: 0.7429\n",
            "Epoch 671/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4265 - accuracy: 0.7955 - val_loss: 0.4349 - val_accuracy: 0.7429\n",
            "Epoch 672/750\n",
            "156/156 [==============================] - 0s 3ms/step - loss: 0.4264 - accuracy: 0.7955 - val_loss: 0.4374 - val_accuracy: 0.7429\n",
            "Epoch 673/750\n",
            "156/156 [==============================] - 0s 3ms/step - loss: 0.4266 - accuracy: 0.7955 - val_loss: 0.4357 - val_accuracy: 0.7429\n",
            "Epoch 674/750\n",
            "156/156 [==============================] - 0s 3ms/step - loss: 0.4264 - accuracy: 0.7971 - val_loss: 0.4375 - val_accuracy: 0.7429\n",
            "Epoch 675/750\n",
            "156/156 [==============================] - 0s 3ms/step - loss: 0.4267 - accuracy: 0.8003 - val_loss: 0.4362 - val_accuracy: 0.7429\n",
            "Epoch 676/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4264 - accuracy: 0.7939 - val_loss: 0.4343 - val_accuracy: 0.7429\n",
            "Epoch 677/750\n",
            "156/156 [==============================] - 0s 3ms/step - loss: 0.4263 - accuracy: 0.7939 - val_loss: 0.4392 - val_accuracy: 0.7429\n",
            "Epoch 678/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4266 - accuracy: 0.7987 - val_loss: 0.4379 - val_accuracy: 0.7429\n",
            "Epoch 679/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4266 - accuracy: 0.7971 - val_loss: 0.4373 - val_accuracy: 0.7429\n",
            "Epoch 680/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4265 - accuracy: 0.7971 - val_loss: 0.4361 - val_accuracy: 0.7429\n",
            "Epoch 681/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4264 - accuracy: 0.7939 - val_loss: 0.4367 - val_accuracy: 0.7429\n",
            "Epoch 682/750\n",
            "156/156 [==============================] - 0s 3ms/step - loss: 0.4265 - accuracy: 0.7971 - val_loss: 0.4376 - val_accuracy: 0.7429\n",
            "Epoch 683/750\n",
            "156/156 [==============================] - 0s 3ms/step - loss: 0.4266 - accuracy: 0.7987 - val_loss: 0.4379 - val_accuracy: 0.7429\n",
            "Epoch 684/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4265 - accuracy: 0.7955 - val_loss: 0.4354 - val_accuracy: 0.7429\n",
            "Epoch 685/750\n",
            "156/156 [==============================] - 0s 3ms/step - loss: 0.4266 - accuracy: 0.7971 - val_loss: 0.4355 - val_accuracy: 0.7429\n",
            "Epoch 686/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4266 - accuracy: 0.7987 - val_loss: 0.4344 - val_accuracy: 0.7429\n",
            "Epoch 687/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4264 - accuracy: 0.7955 - val_loss: 0.4381 - val_accuracy: 0.7429\n",
            "Epoch 688/750\n",
            "156/156 [==============================] - 0s 3ms/step - loss: 0.4265 - accuracy: 0.7955 - val_loss: 0.4340 - val_accuracy: 0.7429\n",
            "Epoch 689/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4266 - accuracy: 0.7987 - val_loss: 0.4338 - val_accuracy: 0.7429\n",
            "Epoch 690/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4265 - accuracy: 0.7923 - val_loss: 0.4358 - val_accuracy: 0.7429\n",
            "Epoch 691/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4266 - accuracy: 0.7987 - val_loss: 0.4356 - val_accuracy: 0.7429\n",
            "Epoch 692/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4268 - accuracy: 0.7971 - val_loss: 0.4364 - val_accuracy: 0.7429\n",
            "Epoch 693/750\n",
            "156/156 [==============================] - 0s 3ms/step - loss: 0.4265 - accuracy: 0.7971 - val_loss: 0.4364 - val_accuracy: 0.7429\n",
            "Epoch 694/750\n",
            "156/156 [==============================] - 0s 3ms/step - loss: 0.4265 - accuracy: 0.7955 - val_loss: 0.4371 - val_accuracy: 0.7429\n",
            "Epoch 695/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4265 - accuracy: 0.7971 - val_loss: 0.4390 - val_accuracy: 0.7429\n",
            "Epoch 696/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4266 - accuracy: 0.7971 - val_loss: 0.4375 - val_accuracy: 0.7429\n",
            "Epoch 697/750\n",
            "156/156 [==============================] - 0s 3ms/step - loss: 0.4265 - accuracy: 0.7955 - val_loss: 0.4336 - val_accuracy: 0.7429\n",
            "Epoch 698/750\n",
            "156/156 [==============================] - 0s 3ms/step - loss: 0.4266 - accuracy: 0.8003 - val_loss: 0.4352 - val_accuracy: 0.7429\n",
            "Epoch 699/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4265 - accuracy: 0.7971 - val_loss: 0.4349 - val_accuracy: 0.7429\n",
            "Epoch 700/750\n",
            "156/156 [==============================] - 0s 3ms/step - loss: 0.4263 - accuracy: 0.7955 - val_loss: 0.4368 - val_accuracy: 0.7429\n",
            "Epoch 701/750\n",
            "156/156 [==============================] - 0s 3ms/step - loss: 0.4263 - accuracy: 0.7987 - val_loss: 0.4402 - val_accuracy: 0.7429\n",
            "Epoch 702/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4264 - accuracy: 0.7955 - val_loss: 0.4378 - val_accuracy: 0.7429\n",
            "Epoch 703/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4264 - accuracy: 0.7971 - val_loss: 0.4353 - val_accuracy: 0.7429\n",
            "Epoch 704/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4265 - accuracy: 0.7987 - val_loss: 0.4347 - val_accuracy: 0.7429\n",
            "Epoch 705/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4265 - accuracy: 0.7987 - val_loss: 0.4354 - val_accuracy: 0.7429\n",
            "Epoch 706/750\n",
            "156/156 [==============================] - 0s 3ms/step - loss: 0.4265 - accuracy: 0.7971 - val_loss: 0.4348 - val_accuracy: 0.7429\n",
            "Epoch 707/750\n",
            "156/156 [==============================] - 0s 3ms/step - loss: 0.4265 - accuracy: 0.7955 - val_loss: 0.4342 - val_accuracy: 0.7429\n",
            "Epoch 708/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4264 - accuracy: 0.7987 - val_loss: 0.4371 - val_accuracy: 0.7429\n",
            "Epoch 709/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4261 - accuracy: 0.8003 - val_loss: 0.4405 - val_accuracy: 0.7429\n",
            "Epoch 710/750\n",
            "156/156 [==============================] - 0s 3ms/step - loss: 0.4265 - accuracy: 0.7923 - val_loss: 0.4364 - val_accuracy: 0.7429\n",
            "Epoch 711/750\n",
            "156/156 [==============================] - 0s 3ms/step - loss: 0.4264 - accuracy: 0.7955 - val_loss: 0.4373 - val_accuracy: 0.7429\n",
            "Epoch 712/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4263 - accuracy: 0.7971 - val_loss: 0.4365 - val_accuracy: 0.7429\n",
            "Epoch 713/750\n",
            "156/156 [==============================] - 0s 3ms/step - loss: 0.4263 - accuracy: 0.7971 - val_loss: 0.4322 - val_accuracy: 0.7429\n",
            "Epoch 714/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4266 - accuracy: 0.7987 - val_loss: 0.4335 - val_accuracy: 0.7429\n",
            "Epoch 715/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4264 - accuracy: 0.7987 - val_loss: 0.4356 - val_accuracy: 0.7429\n",
            "Epoch 716/750\n",
            "156/156 [==============================] - 0s 3ms/step - loss: 0.4262 - accuracy: 0.7987 - val_loss: 0.4358 - val_accuracy: 0.7429\n",
            "Epoch 717/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4264 - accuracy: 0.7987 - val_loss: 0.4403 - val_accuracy: 0.7429\n",
            "Epoch 718/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4262 - accuracy: 0.7971 - val_loss: 0.4405 - val_accuracy: 0.7429\n",
            "Epoch 719/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4264 - accuracy: 0.7939 - val_loss: 0.4382 - val_accuracy: 0.7429\n",
            "Epoch 720/750\n",
            "156/156 [==============================] - 0s 3ms/step - loss: 0.4263 - accuracy: 0.7955 - val_loss: 0.4365 - val_accuracy: 0.7429\n",
            "Epoch 721/750\n",
            "156/156 [==============================] - 0s 3ms/step - loss: 0.4264 - accuracy: 0.7971 - val_loss: 0.4359 - val_accuracy: 0.7429\n",
            "Epoch 722/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4263 - accuracy: 0.7987 - val_loss: 0.4356 - val_accuracy: 0.7429\n",
            "Epoch 723/750\n",
            "156/156 [==============================] - 0s 3ms/step - loss: 0.4262 - accuracy: 0.7955 - val_loss: 0.4358 - val_accuracy: 0.7429\n",
            "Epoch 724/750\n",
            "156/156 [==============================] - 0s 3ms/step - loss: 0.4263 - accuracy: 0.7971 - val_loss: 0.4375 - val_accuracy: 0.7429\n",
            "Epoch 725/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4263 - accuracy: 0.7955 - val_loss: 0.4389 - val_accuracy: 0.7429\n",
            "Epoch 726/750\n",
            "156/156 [==============================] - 0s 3ms/step - loss: 0.4264 - accuracy: 0.7939 - val_loss: 0.4372 - val_accuracy: 0.7429\n",
            "Epoch 727/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4261 - accuracy: 0.7971 - val_loss: 0.4345 - val_accuracy: 0.7429\n",
            "Epoch 728/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4262 - accuracy: 0.7971 - val_loss: 0.4342 - val_accuracy: 0.7429\n",
            "Epoch 729/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4263 - accuracy: 0.8003 - val_loss: 0.4366 - val_accuracy: 0.7429\n",
            "Epoch 730/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4261 - accuracy: 0.7971 - val_loss: 0.4327 - val_accuracy: 0.7429\n",
            "Epoch 731/750\n",
            "156/156 [==============================] - 0s 3ms/step - loss: 0.4265 - accuracy: 0.7955 - val_loss: 0.4352 - val_accuracy: 0.7429\n",
            "Epoch 732/750\n",
            "156/156 [==============================] - 0s 3ms/step - loss: 0.4263 - accuracy: 0.7955 - val_loss: 0.4352 - val_accuracy: 0.7429\n",
            "Epoch 733/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4261 - accuracy: 0.8003 - val_loss: 0.4352 - val_accuracy: 0.7429\n",
            "Epoch 734/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4263 - accuracy: 0.7955 - val_loss: 0.4354 - val_accuracy: 0.7429\n",
            "Epoch 735/750\n",
            "156/156 [==============================] - 0s 3ms/step - loss: 0.4263 - accuracy: 0.7971 - val_loss: 0.4367 - val_accuracy: 0.7429\n",
            "Epoch 736/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4258 - accuracy: 0.8003 - val_loss: 0.4399 - val_accuracy: 0.7429\n",
            "Epoch 737/750\n",
            "156/156 [==============================] - 0s 3ms/step - loss: 0.4263 - accuracy: 0.7971 - val_loss: 0.4378 - val_accuracy: 0.7429\n",
            "Epoch 738/750\n",
            "156/156 [==============================] - 0s 3ms/step - loss: 0.4262 - accuracy: 0.7955 - val_loss: 0.4345 - val_accuracy: 0.7429\n",
            "Epoch 739/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4262 - accuracy: 0.7955 - val_loss: 0.4369 - val_accuracy: 0.7429\n",
            "Epoch 740/750\n",
            "156/156 [==============================] - 0s 3ms/step - loss: 0.4261 - accuracy: 0.7955 - val_loss: 0.4384 - val_accuracy: 0.7429\n",
            "Epoch 741/750\n",
            "156/156 [==============================] - 0s 3ms/step - loss: 0.4261 - accuracy: 0.7971 - val_loss: 0.4427 - val_accuracy: 0.7429\n",
            "Epoch 742/750\n",
            "156/156 [==============================] - 0s 3ms/step - loss: 0.4261 - accuracy: 0.7971 - val_loss: 0.4369 - val_accuracy: 0.7429\n",
            "Epoch 743/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4262 - accuracy: 0.7955 - val_loss: 0.4369 - val_accuracy: 0.7429\n",
            "Epoch 744/750\n",
            "156/156 [==============================] - 0s 3ms/step - loss: 0.4261 - accuracy: 0.7971 - val_loss: 0.4353 - val_accuracy: 0.7429\n",
            "Epoch 745/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4262 - accuracy: 0.7987 - val_loss: 0.4396 - val_accuracy: 0.7429\n",
            "Epoch 746/750\n",
            "156/156 [==============================] - 0s 3ms/step - loss: 0.4263 - accuracy: 0.7955 - val_loss: 0.4365 - val_accuracy: 0.7429\n",
            "Epoch 747/750\n",
            "156/156 [==============================] - 0s 3ms/step - loss: 0.4262 - accuracy: 0.7955 - val_loss: 0.4367 - val_accuracy: 0.7429\n",
            "Epoch 748/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4261 - accuracy: 0.7987 - val_loss: 0.4360 - val_accuracy: 0.7429\n",
            "Epoch 749/750\n",
            "156/156 [==============================] - 0s 3ms/step - loss: 0.4258 - accuracy: 0.7971 - val_loss: 0.4329 - val_accuracy: 0.7429\n",
            "Epoch 750/750\n",
            "156/156 [==============================] - 0s 2ms/step - loss: 0.4262 - accuracy: 0.8003 - val_loss: 0.4349 - val_accuracy: 0.7429\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "80o1i3fzZsA-"
      },
      "source": [
        "**11. Plot the training loss and accuracy**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt \n",
        "acc = hist.history['accuracy']\n",
        "val_acc = hist.history['val_accuracy']\n",
        "loss = hist.history['loss']\n",
        "val_loss = hist.history['val_loss']\n",
        " \n",
        "epochs = range(len(acc))\n",
        " \n",
        "plt.plot(epochs, acc, 'b', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'r', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "plt.savefig('custom_trainvalacc.png')\n",
        "plt.figure()\n",
        " \n",
        "plt.plot(epochs, loss, 'b', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        " \n",
        "#plt.show()\n",
        "plt.savefig('custom_trainvalloss.png')\n",
        "plt.figure()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 580
        },
        "id": "69dOEi6HAiXT",
        "outputId": "8977cbe1-7f58-47d1-a156-3fd070c1510a"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {},
          "execution_count": 29
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a8fUXoqeZvwf"
      },
      "source": [
        "**12. Evaluate the performance**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wawHhkURYMLE",
        "outputId": "86d0b45c-227a-4c51-9591-170f3e64e16d"
      },
      "source": [
        "res =model.evaluate(X_testing, Y_testing)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3/3 [==============================] - 0s 3ms/step - loss: 0.3822 - accuracy: 0.8312\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0WCSw36oZyG_"
      },
      "source": [
        "**13. Predict on new datatset**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CcE27mGFYo3G",
        "outputId": "9ea8d605-b57e-4ad1-9982-1ff2140159c5"
      },
      "source": [
        "test=X_testing[0]\n",
        "y_act=Y_testing[0]\n",
        "result=model.predict(test.reshape(1,8))\n",
        "result"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.66763544, 0.3323645 ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T4RDC-ZHYqv_",
        "outputId": "3b7030d0-f250-4a2d-b624-29583bc0b11c"
      },
      "source": [
        "import numpy as np\n",
        "y_pred = np.round(result)\n",
        "print(\"Actual:\"+ str(y_act))\n",
        "print(\"Predicted:\"+str(y_pred))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Actual:[1. 0.]\n",
            "Predicted:[[1. 0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E9mMqJtXYz2Q"
      },
      "source": [
        "**Reference:** - https://keras.io/"
      ]
    }
  ]
}